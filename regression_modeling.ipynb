{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Comprehensive Regression Modeling: Ames Housing Dataset\n",
    "\n",
    "This notebook provides a complete end-to-end regression modeling pipeline using the Ames Housing dataset. We'll cover:\n",
    "\n",
    "1. **Data Exploration & Understanding**\n",
    "2. **Feature Engineering & Selection** \n",
    "3. **Model Selection & Training**\n",
    "4. **Model Evaluation & Validation**\n",
    "5. **Model Interpretation & Insights**\n",
    "6. **Advanced Techniques & Optimization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "w8xbr4ao1qq",
   "source": "### üì¶ Library Imports and Environment Setup\n\nThis cell imports all the essential libraries we'll need for our comprehensive regression modeling pipeline. Each library serves a specific purpose:\n\n**Why these libraries?**\n- **pandas & numpy**: Core data manipulation and numerical computation\n- **matplotlib & seaborn**: Professional data visualization\n- **scipy**: Statistical analysis and data transformations\n- **scikit-learn**: Complete machine learning ecosystem\n- **XGBoost/LightGBM**: State-of-the-art gradient boosting (if available)\n\nThe imports are organized by category to make the code readable and maintainable. We also configure display settings and visualization styles for consistent, professional output throughout the notebook.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": "# Import essential libraries\n# Data manipulation and analysis\nimport pandas as pd  # For data manipulation and analysis\nimport numpy as np   # For numerical computations and array operations\n\n# Visualization libraries\nimport matplotlib.pyplot as plt  # For creating static plots and visualizations\nimport seaborn as sns            # For statistical data visualization with attractive defaults\n\n# Statistical analysis\nimport warnings                           # To suppress unnecessary warnings\nfrom scipy import stats                   # For statistical functions and tests\nfrom scipy.stats import skew, boxcox_normmax  # For distribution analysis and transformation\nfrom scipy.special import boxcox1p        # For Box-Cox transformation with lambda parameter\n\n# Machine Learning libraries from scikit-learn\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n# train_test_split: Split data into training and testing sets\n# cross_val_score: Perform k-fold cross-validation\n# GridSearchCV/RandomizedSearchCV: Hyperparameter tuning methods\n\nfrom sklearn.preprocessing import StandardScaler, RobustScaler, LabelEncoder, OneHotEncoder\n# StandardScaler: Standardize features to mean=0, std=1\n# RobustScaler: Scale features using median and IQR (robust to outliers)\n# LabelEncoder: Convert categorical labels to numerical values\n# OneHotEncoder: Create binary columns for categorical variables\n\nfrom sklearn.feature_selection import SelectKBest, f_regression, RFE, SelectFromModel\n# SelectKBest: Select k highest scoring features\n# f_regression: F-statistic for regression feature selection\n# RFE: Recursive Feature Elimination\n# SelectFromModel: Select features based on model coefficients/importance\n\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n# LinearRegression: Basic linear regression without regularization\n# Ridge: L2 regularization to prevent overfitting\n# Lasso: L1 regularization for feature selection\n# ElasticNet: Combines L1 and L2 regularization\n\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n# RandomForest: Ensemble of decision trees with bagging\n# GradientBoosting: Sequential ensemble that corrects previous model errors\n# ExtraTrees: Extremely randomized trees for faster training\n\nfrom sklearn.svm import SVR                    # Support Vector Regression\nfrom sklearn.neighbors import KNeighborsRegressor  # k-Nearest Neighbors regression\n\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n# Evaluation metrics for regression models\n\nfrom sklearn.pipeline import Pipeline          # For creating ML pipelines\nfrom sklearn.compose import ColumnTransformer  # For applying different transformations to different columns\n\n# Advanced gradient boosting libraries (optional but powerful)\ntry:\n    import xgboost as xgb\n    xgb_available = True\n    print(\"XGBoost imported successfully - enables powerful gradient boosting\")\nexcept ImportError:\n    print(\"XGBoost not available. Install with: pip install xgboost\")\n    xgb_available = False\n\ntry:\n    import lightgbm as lgb\n    lgb_available = True\n    print(\"LightGBM imported successfully - enables fast gradient boosting\")\nexcept ImportError:\n    print(\"LightGBM not available. Install with: pip install lightgbm\")\n    lgb_available = False\n\n# Configure environment settings\nwarnings.filterwarnings('ignore')  # Suppress warnings for cleaner output\n\n# Set consistent visualization style\nplt.style.use('seaborn-v0_8')  # Modern, clean plotting style\nsns.set_palette(\"husl\")         # Use attractive color palette\n\n# Configure pandas display options for better data exploration\npd.set_option('display.max_columns', None)  # Show all columns when displaying DataFrames\npd.set_option('display.max_rows', 100)      # Show up to 100 rows\n\nprint(\"‚úÖ All libraries imported successfully!\")\nprint(f\"XGBoost available: {xgb_available}\")\nprint(f\"LightGBM available: {lgb_available}\")\nprint(\"\\nüìö Libraries loaded for comprehensive regression modeling:\")\nprint(\"   ‚Ä¢ Data processing: pandas, numpy\")\nprint(\"   ‚Ä¢ Visualization: matplotlib, seaborn\")\nprint(\"   ‚Ä¢ ML algorithms: 9+ regression models from scikit-learn\")\nprint(\"   ‚Ä¢ Feature engineering: preprocessing and selection tools\")\nprint(\"   ‚Ä¢ Model evaluation: comprehensive metrics and validation\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": "# Load the Ames Housing dataset and perform initial inspection\n# The Ames Housing dataset is a comprehensive dataset of residential properties in Ames, Iowa\n# It contains detailed information about house characteristics and sale prices\ndf = pd.read_csv('datasets/AmesHousing.csv')\n\n# Display basic dataset information\nprint(f\"üè† Ames Housing Dataset loaded successfully!\")\nprint(f\"Shape: {df.shape} (rows √ó columns)\")\nprint(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n\n# Perform initial data quality checks\nprint(\"\\n=== DATASET OVERVIEW ===\")\nprint(f\"Total samples: {df.shape[0]:,}\")           # Number of house records\nprint(f\"Total features: {df.shape[1]}\")            # Number of variables/columns\nprint(f\"Duplicate rows: {df.duplicated().sum()}\")  # Check for exact duplicates\n\n# Display first few rows to understand data structure\nprint(\"\\n=== SAMPLE DATA (First 3 Rows) ===\")\nprint(\"This gives us a preview of the data structure and types:\")\ndisplay(df.head(3))\n\n# Quick info about data types\nprint(f\"\\n=== DATA TYPE SUMMARY ===\")\nprint(f\"Numerical columns: {len(df.select_dtypes(include=[np.number]).columns)}\")\nprint(f\"Categorical columns: {len(df.select_dtypes(include=['object']).columns)}\")\n\nprint(\"\\n‚úÖ Initial data loading completed successfully!\")\nprint(\"Next: We'll analyze our target variable (SalePrice) in detail\")"
  },
  {
   "cell_type": "markdown",
   "id": "b0gydu0303j",
   "source": "### üìä Data Loading and Initial Inspection\n\nLoading the Ames Housing dataset and performing initial data quality checks. This step is crucial because it helps us understand:\n\n- **Dataset size**: Number of rows and columns\n- **Memory usage**: Important for large datasets\n- **Data integrity**: Checking for duplicates\n- **Basic structure**: Getting familiar with the data format\n\nThe `display()` function shows the first few rows in a formatted table, giving us a quick preview of our features and data types.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 2. Initial Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "at4er9mvzph",
   "source": "### üéØ Target Variable Analysis\n\nUnderstanding our target variable (SalePrice) is fundamental to building an effective regression model. This analysis helps us:\n\n- **Identify the data distribution**: Is it normal, skewed, or has outliers?\n- **Detect transformation needs**: Skewed data often benefits from log transformation\n- **Understand the scale**: Price ranges help us set realistic expectations\n- **Check for data quality issues**: Missing values, extreme outliers, etc.\n\nThe visualizations show:\n1. **Histogram**: Overall distribution shape\n2. **Box plot**: Outliers and quartiles\n3. **Q-Q plot**: How closely the data follows a normal distribution\n4. **Log-transformed histogram**: Shows if log transformation improves normality",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": "# Comprehensive analysis of our target variable: SalePrice\n# This is the variable we want to predict, so understanding it deeply is crucial\ntarget = 'SalePrice'\n\nprint(\"=== TARGET VARIABLE ANALYSIS: SalePrice ===\")\nprint(f\"Target variable: {target}\")\n\n# Calculate descriptive statistics to understand the distribution\nprint(f\"\\nüìä DESCRIPTIVE STATISTICS:\")\ntarget_stats = df[target].describe()\nprint(target_stats)\n\n# Calculate distribution characteristics\n# Skewness: measures asymmetry (0 = symmetric, >0 = right-skewed, <0 = left-skewed)\n# Kurtosis: measures tail heaviness (3 = normal distribution)\nskewness = df[target].skew()\nkurtosis = df[target].kurtosis()\nmissing_count = df[target].isnull().sum()\n\nprint(f\"\\nüìà DISTRIBUTION CHARACTERISTICS:\")\nprint(f\"Skewness: {skewness:.4f} {'(right-skewed)' if skewness > 0.5 else '(approximately symmetric)' if abs(skewness) < 0.5 else '(left-skewed)'}\")\nprint(f\"Kurtosis: {kurtosis:.4f} {'(heavy tails)' if kurtosis > 3 else '(light tails)' if kurtosis < 3 else '(normal tails)'}\")\nprint(f\"Missing values: {missing_count} ({missing_count/len(df)*100:.1f}%)\")\n\n# Create comprehensive visualizations to understand the distribution\nfig, axes = plt.subplots(2, 2, figsize=(15, 10))\nfig.suptitle('SalePrice Distribution Analysis', fontsize=16, y=1.02)\n\n# 1. Histogram - shows the overall shape of the distribution\naxes[0,0].hist(df[target], bins=50, edgecolor='black', alpha=0.7, color='skyblue')\naxes[0,0].set_title('SalePrice Distribution\\n(Original Scale)')\naxes[0,0].set_xlabel('Sale Price ($)')\naxes[0,0].set_ylabel('Frequency')\naxes[0,0].axvline(df[target].mean(), color='red', linestyle='--', label=f'Mean: ${df[target].mean():,.0f}')\naxes[0,0].axvline(df[target].median(), color='orange', linestyle='--', label=f'Median: ${df[target].median():,.0f}')\naxes[0,0].legend()\n\n# 2. Box plot - excellent for identifying outliers and quartiles\nbox_data = axes[0,1].boxplot(df[target])\naxes[0,1].set_title('SalePrice Box Plot\\n(Outlier Detection)')\naxes[0,1].set_ylabel('Sale Price ($)')\naxes[0,1].grid(True, alpha=0.3)\n\n# 3. Q-Q plot - compares our data to a theoretical normal distribution\nstats.probplot(df[target], dist=\"norm\", plot=axes[1,0])\naxes[1,0].set_title('Q-Q Plot vs Normal Distribution\\n(Normality Check)')\naxes[1,0].grid(True, alpha=0.3)\n\n# 4. Log-transformed distribution - often improves normality for price data\nlog_prices = np.log1p(df[target])  # log1p = log(1+x) to handle zeros safely\naxes[1,1].hist(log_prices, bins=50, edgecolor='black', alpha=0.7, color='lightgreen')\naxes[1,1].set_title('Log-Transformed SalePrice\\n(Improved Normality)')\naxes[1,1].set_xlabel('Log(Sale Price)')\naxes[1,1].set_ylabel('Frequency')\naxes[1,1].axvline(log_prices.mean(), color='red', linestyle='--', label=f'Mean: {log_prices.mean():.2f}')\naxes[1,1].legend()\n\nplt.tight_layout()\nplt.show()\n\n# Compare skewness before and after log transformation\nlog_skewness = log_prices.skew()\nprint(f\"\\nüîÑ TRANSFORMATION IMPACT:\")\nprint(f\"Original skewness: {skewness:.4f}\")\nprint(f\"Log-transformed skewness: {log_skewness:.4f}\")\nprint(f\"Improvement: {'‚úÖ Significant' if abs(log_skewness) < abs(skewness) * 0.5 else '‚ö†Ô∏è Moderate' if abs(log_skewness) < abs(skewness) else '‚ùå None'}\")\n\nprint(f\"\\nüí° KEY INSIGHTS:\")\nprint(f\"   ‚Ä¢ Price range: ${df[target].min():,.0f} to ${df[target].max():,.0f}\")\nprint(f\"   ‚Ä¢ Mean price: ${df[target].mean():,.0f}\")\nprint(f\"   ‚Ä¢ Median price: ${df[target].median():,.0f}\")\nprint(f\"   ‚Ä¢ Standard deviation: ${df[target].std():,.0f}\")\nif skewness > 0.5:\n    print(f\"   ‚Ä¢ Distribution is right-skewed ‚Üí Log transformation recommended\")\nelse:\n    print(f\"   ‚Ä¢ Distribution is approximately symmetric ‚Üí Transformation may not be needed\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": "# Comprehensive analysis of data types and missing values\n# Understanding our feature landscape is essential for preprocessing and model selection\nprint(\"=== DATA TYPES AND MISSING VALUES ANALYSIS ===\")\n\n# Separate features by data type - this determines how we'll preprocess them\nnumerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\ncategorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n\n# Remove target variable from numerical columns for feature analysis\nif target in numerical_cols:\n    numerical_cols.remove(target)\n\nprint(f\"\\nüìä FEATURE TYPE BREAKDOWN:\")\nprint(f\"Numerical features: {len(numerical_cols)} columns\")\nprint(f\"Categorical features: {len(categorical_cols)} columns\")\nprint(f\"Total features (excluding target): {len(numerical_cols) + len(categorical_cols)}\")\n\n# Analyze missing values across all columns\n# Create a comprehensive missing values report\nmissing_data = pd.DataFrame({\n    'Column': df.columns,\n    'Missing_Count': df.isnull().sum(),\n    'Missing_Percentage': (df.isnull().sum() / len(df)) * 100,\n    'Data_Type': df.dtypes\n})\n\n# Focus on columns with missing values\nmissing_data = missing_data[missing_data['Missing_Count'] > 0]\nmissing_data = missing_data.sort_values('Missing_Percentage', ascending=False)\n\nprint(f\"\\nüîç MISSING VALUES SUMMARY:\")\nprint(f\"Columns with missing values: {len(missing_data)}\")\nprint(f\"Total missing values: {missing_data['Missing_Count'].sum():,}\")\nprint(f\"Overall missing percentage: {(missing_data['Missing_Count'].sum() / (len(df) * len(df.columns))) * 100:.2f}%\")\n\nif len(missing_data) > 0:\n    print(f\"\\nüìã TOP COLUMNS WITH MISSING VALUES:\")\n    print(\"=\" * 80)\n    for _, row in missing_data.head(10).iterrows():\n        col_name = row['Column'][:25].ljust(25)  # Truncate long names\n        missing_pct = row['Missing_Percentage']\n        missing_count = int(row['Missing_Count'])\n        data_type = str(row['Data_Type'])\n        \n        # Add interpretation\n        severity = \"üî¥ High\" if missing_pct > 20 else \"üü° Medium\" if missing_pct > 5 else \"üü¢ Low\"\n        \n        print(f\"  {col_name} | {missing_count:>4} ({missing_pct:>5.1f}%) | {data_type:<8} | {severity}\")\n    \n    # Create visualization of missing values\n    if len(missing_data) > 0:\n        plt.figure(figsize=(12, 6))\n        top_missing = missing_data.head(15)\n        plt.barh(range(len(top_missing)), top_missing['Missing_Percentage'])\n        plt.yticks(range(len(top_missing)), top_missing['Column'])\n        plt.xlabel('Missing Percentage (%)')\n        plt.title('Top 15 Features with Missing Values')\n        plt.gca().invert_yaxis()\n        \n        # Add percentage labels\n        for i, v in enumerate(top_missing['Missing_Percentage']):\n            plt.text(v + 0.5, i, f'{v:.1f}%', va='center')\n        \n        plt.tight_layout()\n        plt.show()\nelse:\n    print(\"‚úÖ Excellent! No missing values found in the dataset!\")\n\n# Analyze the distribution of missing values by data type\nprint(f\"\\nüìà MISSING VALUES BY DATA TYPE:\")\nif len(missing_data) > 0:\n    missing_by_type = missing_data.groupby('Data_Type').agg({\n        'Missing_Count': ['count', 'sum', 'mean'],\n        'Missing_Percentage': 'mean'\n    }).round(2)\n    print(missing_by_type)\nelse:\n    print(\"No missing values to analyze by type.\")\n\nprint(f\"\\nüí° PREPROCESSING IMPLICATIONS:\")\nprint(f\"   ‚Ä¢ Numerical features ({len(numerical_cols)}): Ready for scaling and transformation\")\nprint(f\"   ‚Ä¢ Categorical features ({len(categorical_cols)}): Need encoding (one-hot, target, etc.)\")\nif len(missing_data) > 0:\n    high_missing = len(missing_data[missing_data['Missing_Percentage'] > 20])\n    print(f\"   ‚Ä¢ High missing features ({high_missing}): Consider dropping or advanced imputation\")\n    print(f\"   ‚Ä¢ Strategy needed: Domain-specific imputation for each feature type\")\nelse:\n    print(f\"   ‚Ä¢ No missing values: Can proceed directly to feature engineering\")"
  },
  {
   "cell_type": "markdown",
   "id": "7fdfhmm7hzk",
   "source": "### üîç Data Types and Missing Values Analysis\n\nBefore building models, we need to understand our feature landscape:\n\n**Why this analysis matters:**\n- **Numerical features**: Can be used directly in most ML algorithms\n- **Categorical features**: Need encoding (one-hot, target encoding, etc.)\n- **Missing values**: Must be handled appropriately for each feature type\n\n**Missing values strategy:**\n- **Numerical**: Often filled with median (robust to outliers) or mean\n- **Categorical**: Filled with mode (most frequent) or 'Unknown'/'None'\n- **Domain knowledge**: Some missing values are actually meaningful (e.g., no garage = missing garage features)\n\nThis analysis guides our preprocessing pipeline and feature engineering strategy.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": "## 3. Feature Engineering\n\nFeature engineering is often the most impactful part of the machine learning pipeline. Good features can make a simple model outperform a complex one with poor features.\n\n**Our comprehensive approach includes:**\n\n1. **Strategic Missing Value Handling**: Different strategies for different feature types\n2. **Domain-Specific Feature Creation**: Combining existing features to create meaningful new ones\n3. **Data Transformations**: Normalizing skewed distributions for better model performance\n\n**Why Feature Engineering Matters:**\n- **Improves Model Performance**: Better features ‚Üí better predictions\n- **Captures Domain Knowledge**: Meaningful combinations often outperform raw features  \n- **Handles Data Quality Issues**: Proper missing value treatment prevents errors\n- **Enables Better Model Interpretation**: Clear, meaningful features are easier to explain\n\nFeature engineering is both an art and a science - we use statistical techniques guided by domain knowledge about real estate."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for feature engineering\n",
    "df_fe = df.copy()\n",
    "\n",
    "print(\"=== FEATURE ENGINEERING ===\")\n",
    "\n",
    "# 1. Handle missing values strategically\n",
    "print(\"\\n1. Handling Missing Values...\")\n",
    "\n",
    "# For numerical features, fill with median or 0 based on context\n",
    "numerical_fill_median = [col for col in numerical_cols if col in df_fe.columns and df_fe[col].isnull().sum() > 0]\n",
    "for col in numerical_fill_median:\n",
    "    if 'Area' in col or 'SF' in col:  # Area features can be 0\n",
    "        df_fe[col].fillna(0, inplace=True)\n",
    "    else:\n",
    "        df_fe[col].fillna(df_fe[col].median(), inplace=True)\n",
    "\n",
    "# For categorical features, fill with 'None' or mode\n",
    "categorical_fill = [col for col in categorical_cols if col in df_fe.columns and df_fe[col].isnull().sum() > 0]\n",
    "for col in categorical_fill:\n",
    "    # Features that logically can be 'None'\n",
    "    if any(keyword in col for keyword in ['Garage', 'Bsmt', 'Fireplace', 'Pool', 'Fence', 'Alley']):\n",
    "        df_fe[col].fillna('None', inplace=True)\n",
    "    else:\n",
    "        df_fe[col].fillna(df_fe[col].mode()[0] if len(df_fe[col].mode()) > 0 else 'Unknown', inplace=True)\n",
    "\n",
    "print(f\"   ‚úÖ Missing values handled\")\n",
    "\n",
    "# 2. Create new features\n",
    "print(\"\\n2. Creating New Features...\")\n",
    "\n",
    "# Total square footage\n",
    "area_cols = [col for col in df_fe.columns if 'SF' in col and col != target]\n",
    "if len(area_cols) > 0:\n",
    "    df_fe['TotalSF'] = df_fe[area_cols].sum(axis=1)\n",
    "    print(f\"   ‚úÖ TotalSF created from {len(area_cols)} area columns\")\n",
    "\n",
    "# House age and remodel age\n",
    "if 'Year Built' in df_fe.columns and 'Yr Sold' in df_fe.columns:\n",
    "    df_fe['HouseAge'] = df_fe['Yr Sold'] - df_fe['Year Built']\n",
    "    print(f\"   ‚úÖ HouseAge created\")\n",
    "\n",
    "if 'Year Remod/Add' in df_fe.columns and 'Yr Sold' in df_fe.columns:\n",
    "    df_fe['RemodAge'] = df_fe['Yr Sold'] - df_fe['Year Remod/Add']\n",
    "    df_fe['WasRemodeled'] = (df_fe['Year Remod/Add'] != df_fe['Year Built']).astype(int)\n",
    "    print(f\"   ‚úÖ RemodAge and WasRemodeled created\")\n",
    "\n",
    "# Total bathrooms\n",
    "bathroom_cols = [col for col in df_fe.columns if 'Bath' in col]\n",
    "if len(bathroom_cols) > 0:\n",
    "    # Give half baths 0.5 weight\n",
    "    df_fe['TotalBaths'] = 0\n",
    "    for col in bathroom_cols:\n",
    "        if 'Half' in col:\n",
    "            df_fe['TotalBaths'] += df_fe[col] * 0.5\n",
    "        else:\n",
    "            df_fe['TotalBaths'] += df_fe[col]\n",
    "    print(f\"   ‚úÖ TotalBaths created from {len(bathroom_cols)} bathroom columns\")\n",
    "\n",
    "# Quality score (combine overall quality and condition)\n",
    "if 'Overall Qual' in df_fe.columns and 'Overall Cond' in df_fe.columns:\n",
    "    df_fe['QualityScore'] = df_fe['Overall Qual'] * df_fe['Overall Cond']\n",
    "    print(f\"   ‚úÖ QualityScore created\")\n",
    "\n",
    "# Garage score\n",
    "garage_cols = [col for col in df_fe.columns if 'Garage' in col and df_fe[col].dtype in ['int64', 'float64']]\n",
    "if len(garage_cols) > 0:\n",
    "    df_fe['GarageScore'] = df_fe[garage_cols].sum(axis=1)\n",
    "    print(f\"   ‚úÖ GarageScore created\")\n",
    "\n",
    "print(f\"\\nOriginal features: {df.shape[1]}\")\n",
    "print(f\"After feature engineering: {df_fe.shape[1]}\")\n",
    "print(f\"New features created: {df_fe.shape[1] - df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Transform skewed features\n",
    "print(\"=== FEATURE TRANSFORMATION ===\")\n",
    "\n",
    "# Update numerical columns list\n",
    "numerical_cols = df_fe.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if target in numerical_cols:\n",
    "    numerical_cols.remove(target)\n",
    "\n",
    "# Find skewed features\n",
    "skewed_features = []\n",
    "for col in numerical_cols:\n",
    "    if df_fe[col].dtype in ['int64', 'float64']:\n",
    "        skewness = df_fe[col].skew()\n",
    "        if abs(skewness) > 0.75:  # Threshold for significant skewness\n",
    "            skewed_features.append((col, skewness))\n",
    "\n",
    "print(f\"\\nFound {len(skewed_features)} skewed features:\")\n",
    "skewed_df = pd.DataFrame(skewed_features, columns=['Feature', 'Skewness']).sort_values('Skewness', key=abs, ascending=False)\n",
    "print(skewed_df.head(10).to_string(index=False))\n",
    "\n",
    "# Apply Box-Cox transformation to positive skewed features\n",
    "print(\"\\nApplying transformations...\")\n",
    "transformed_features = []\n",
    "\n",
    "for col, skewness in skewed_features:\n",
    "    if df_fe[col].min() > 0:  # Box-Cox requires positive values\n",
    "        # Use Box-Cox transformation\n",
    "        lam = boxcox_normmax(df_fe[col] + 1)  # Add 1 to handle zeros\n",
    "        df_fe[col] = boxcox1p(df_fe[col], lam)\n",
    "        transformed_features.append(col)\n",
    "    elif skewness > 0:  # Positive skew, use log transformation\n",
    "        df_fe[col] = np.log1p(df_fe[col])\n",
    "        transformed_features.append(col)\n",
    "\n",
    "print(f\"‚úÖ Transformed {len(transformed_features)} features\")\n",
    "\n",
    "# Transform target variable\n",
    "df_fe['SalePrice_log'] = np.log1p(df_fe[target])\n",
    "print(f\"‚úÖ Target variable log-transformed\")\n",
    "print(f\"   Original skewness: {df_fe[target].skew():.4f}\")\n",
    "print(f\"   Transformed skewness: {df_fe['SalePrice_log'].skew():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## 4. Feature Selection\n",
    "\n",
    "Feature selection is crucial for model performance and interpretability. We'll use multiple methods to identify the most important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for feature selection\n",
    "print(\"=== FEATURE SELECTION ===\")\n",
    "\n",
    "# Update column lists\n",
    "numerical_cols = df_fe.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = df_fe.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Remove target variables from features\n",
    "exclude_cols = [target, 'SalePrice_log', 'Order', 'PID']  # Remove ID columns\n",
    "numerical_cols = [col for col in numerical_cols if col not in exclude_cols]\n",
    "\n",
    "print(f\"Numerical features: {len(numerical_cols)}\")\n",
    "print(f\"Categorical features: {len(categorical_cols)}\")\n",
    "\n",
    "# 1. Correlation-based feature selection for numerical features\n",
    "print(\"\\n1. Correlation Analysis...\")\n",
    "\n",
    "# Calculate correlation with target\n",
    "correlations = df_fe[numerical_cols + [target]].corr()[target].abs().sort_values(ascending=False)\n",
    "high_corr_features = correlations[correlations > 0.3].drop(target).head(20)\n",
    "\n",
    "print(f\"Top 15 features by correlation with {target}:\")\n",
    "for feature, corr in high_corr_features.head(15).items():\n",
    "    print(f\"  {feature:25}: {corr:.4f}\")\n",
    "\n",
    "# Visualize top correlations\n",
    "plt.figure(figsize=(12, 8))\n",
    "high_corr_features.head(15).plot(kind='barh')\n",
    "plt.title('Top 15 Features by Correlation with SalePrice')\n",
    "plt.xlabel('Absolute Correlation')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Handle categorical variables with encoding\n",
    "print(\"\\n2. Categorical Variable Encoding...\")\n",
    "\n",
    "# For categorical features, we'll use target encoding for high-cardinality features\n",
    "# and one-hot encoding for low-cardinality features\n",
    "\n",
    "df_encoded = df_fe.copy()\n",
    "encoded_features = []\n",
    "\n",
    "for col in categorical_cols:\n",
    "    unique_count = df_fe[col].nunique()\n",
    "    \n",
    "    if unique_count > 10:  # High cardinality - use target encoding\n",
    "        # Target encoding (mean of target for each category)\n",
    "        target_mean = df_fe.groupby(col)[target].mean()\n",
    "        df_encoded[f\"{col}_encoded\"] = df_fe[col].map(target_mean)\n",
    "        encoded_features.append(f\"{col}_encoded\")\n",
    "        print(f\"  Target encoded: {col} ({unique_count} categories)\")\n",
    "    \n",
    "    elif unique_count > 2:  # Medium cardinality - use one-hot encoding\n",
    "        # One-hot encoding\n",
    "        dummies = pd.get_dummies(df_fe[col], prefix=col, drop_first=True)\n",
    "        df_encoded = pd.concat([df_encoded, dummies], axis=1)\n",
    "        encoded_features.extend(dummies.columns.tolist())\n",
    "        print(f\"  One-hot encoded: {col} ({unique_count} categories -> {len(dummies.columns)} features)\")\n",
    "    \n",
    "    else:  # Binary - use label encoding\n",
    "        le = LabelEncoder()\n",
    "        df_encoded[f\"{col}_encoded\"] = le.fit_transform(df_fe[col])\n",
    "        encoded_features.append(f\"{col}_encoded\")\n",
    "        print(f\"  Label encoded: {col} ({unique_count} categories)\")\n",
    "\n",
    "# Remove original categorical columns\n",
    "df_encoded.drop(columns=categorical_cols, inplace=True)\n",
    "\n",
    "print(f\"\\n‚úÖ Categorical encoding completed\")\n",
    "print(f\"  Original categorical features: {len(categorical_cols)}\")\n",
    "print(f\"  Encoded features created: {len(encoded_features)}\")\n",
    "print(f\"  Total features after encoding: {df_encoded.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Statistical feature selection\n",
    "print(\"\\n3. Statistical Feature Selection...\")\n",
    "\n",
    "# Prepare feature matrix\n",
    "feature_cols = [col for col in df_encoded.columns if col not in [target, 'SalePrice_log']]\n",
    "X = df_encoded[feature_cols]\n",
    "y = df_encoded[target]\n",
    "\n",
    "# Handle any remaining missing values\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "\n",
    "# SelectKBest with f_regression\n",
    "selector_f = SelectKBest(score_func=f_regression, k=50)  # Select top 50 features\n",
    "X_selected_f = selector_f.fit_transform(X, y)\n",
    "selected_features_f = X.columns[selector_f.get_support()].tolist()\n",
    "\n",
    "print(f\"\\nF-regression selected features: {len(selected_features_f)}\")\n",
    "print(\"Top 10 by F-score:\")\n",
    "feature_scores = list(zip(selected_features_f, selector_f.scores_[selector_f.get_support()]))\n",
    "feature_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "for feature, score in feature_scores[:10]:\n",
    "    print(f\"  {feature:30}: {score:.2f}\")\n",
    "\n",
    "# Tree-based feature selection\n",
    "print(\"\\n4. Tree-based Feature Importance...\")\n",
    "rf_selector = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_selector.fit(X, y)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importance = list(zip(X.columns, rf_selector.feature_importances_))\n",
    "feature_importance.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Top 10 by Random Forest importance:\")\n",
    "for feature, importance in feature_importance[:10]:\n",
    "    print(f\"  {feature:30}: {importance:.4f}\")\n",
    "\n",
    "# Select top features from Random Forest\n",
    "rf_top_features = [feature for feature, _ in feature_importance[:50]]\n",
    "\n",
    "# Combine selections\n",
    "combined_features = list(set(selected_features_f + rf_top_features))\n",
    "print(f\"\\n‚úÖ Combined feature selection: {len(combined_features)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "# Random Forest Feature Importance\n",
    "top_rf_features = feature_importance[:15]\n",
    "features_rf = [f[0] for f in top_rf_features]\n",
    "importances_rf = [f[1] for f in top_rf_features]\n",
    "\n",
    "axes[0].barh(range(len(features_rf)), importances_rf)\n",
    "axes[0].set_yticks(range(len(features_rf)))\n",
    "axes[0].set_yticklabels(features_rf)\n",
    "axes[0].set_xlabel('Importance')\n",
    "axes[0].set_title('Top 15 Features - Random Forest Importance')\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "# F-regression scores\n",
    "top_f_scores = feature_scores[:15]\n",
    "features_f = [f[0] for f in top_f_scores]\n",
    "scores_f = [f[1] for f in top_f_scores]\n",
    "\n",
    "axes[1].barh(range(len(features_f)), scores_f)\n",
    "axes[1].set_yticks(range(len(features_f)))\n",
    "axes[1].set_yticklabels(features_f)\n",
    "axes[1].set_xlabel('F-Score')\n",
    "axes[1].set_title('Top 15 Features - F-Regression Score')\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create final feature set\n",
    "final_features = combined_features\n",
    "print(f\"\\nüéØ Final feature set: {len(final_features)} features\")\n",
    "print(f\"Selected features: {final_features[:10]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## 5. Model Selection and Training\n",
    "\n",
    "We'll train multiple regression models and compare their performance using cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare final dataset for modeling\n",
    "print(\"=== MODEL PREPARATION ===\")\n",
    "\n",
    "# Create final feature matrix\n",
    "X_final = df_encoded[final_features]\n",
    "y_final = df_encoded['SalePrice_log']  # Use log-transformed target\n",
    "\n",
    "# Handle any remaining missing values\n",
    "X_final = X_final.fillna(X_final.median())\n",
    "\n",
    "print(f\"Final dataset shape: {X_final.shape}\")\n",
    "print(f\"Target shape: {y_final.shape}\")\n",
    "print(f\"Missing values in features: {X_final.isnull().sum().sum()}\")\n",
    "print(f\"Missing values in target: {y_final.isnull().sum()}\")\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_final, y_final, test_size=0.2, random_state=42, stratify=pd.cut(y_final, bins=5)\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Scale features for linear models\n",
    "scaler = RobustScaler()  # Less sensitive to outliers than StandardScaler\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"‚úÖ Data prepared for modeling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models to test\n",
    "print(\"=== MODEL SELECTION ===\")\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge': Ridge(random_state=42),\n",
    "    'Lasso': Lasso(random_state=42),\n",
    "    'ElasticNet': ElasticNet(random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42, n_jobs=-1),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n",
    "    'Extra Trees': ExtraTreesRegressor(random_state=42, n_jobs=-1),\n",
    "    'KNN': KNeighborsRegressor(n_jobs=-1),\n",
    "    'SVR': SVR()\n",
    "}\n",
    "\n",
    "# Add XGBoost and LightGBM if available\n",
    "if xgb_available:\n",
    "    models['XGBoost'] = xgb.XGBRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "if lgb_available:\n",
    "    models['LightGBM'] = lgb.LGBMRegressor(random_state=42, n_jobs=-1, verbose=-1)\n",
    "\n",
    "print(f\"\\nTesting {len(models)} models:\")\n",
    "for name in models.keys():\n",
    "    print(f\"  ‚Ä¢ {name}\")\n",
    "\n",
    "# Models that need scaled features\n",
    "scaled_models = ['Linear Regression', 'Ridge', 'Lasso', 'ElasticNet', 'KNN', 'SVR']\n",
    "\n",
    "# Cross-validation function\n",
    "def evaluate_model(model, X_train, y_train, model_name, cv_folds=5):\n",
    "    \"\"\"Evaluate model using cross-validation\"\"\"\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=cv_folds, \n",
    "                            scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    rmse_scores = np.sqrt(-scores)\n",
    "    \n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'mean_rmse': rmse_scores.mean(),\n",
    "        'std_rmse': rmse_scores.std(),\n",
    "        'min_rmse': rmse_scores.min(),\n",
    "        'max_rmse': rmse_scores.max()\n",
    "    }\n",
    "\n",
    "# Evaluate all models\n",
    "print(\"\\nEvaluating models (5-fold CV)...\")\n",
    "model_results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n  Training {name}...\")\n",
    "    \n",
    "    # Use scaled features for linear models\n",
    "    if name in scaled_models:\n",
    "        X_train_input = X_train_scaled\n",
    "    else:\n",
    "        X_train_input = X_train\n",
    "    \n",
    "    try:\n",
    "        result = evaluate_model(model, X_train_input, y_train, name)\n",
    "        model_results.append(result)\n",
    "        print(f\"    RMSE: {result['mean_rmse']:.4f} (+/- {result['std_rmse']:.4f})\")\n",
    "    except Exception as e:\n",
    "        print(f\"    ‚ùå Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL COMPARISON RESULTS\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "results_df = pd.DataFrame(model_results)\n",
    "results_df = results_df.sort_values('mean_rmse')\n",
    "\n",
    "print(\"\\nCross-Validation Results (RMSE on log-transformed prices):\")\n",
    "print(results_df.to_string(index=False, float_format='%.4f'))\n",
    "\n",
    "# Visualize results\n",
    "plt.figure(figsize=(12, 8))\n",
    "y_pos = range(len(results_df))\n",
    "plt.barh(y_pos, results_df['mean_rmse'], xerr=results_df['std_rmse'], \n",
    "         alpha=0.7, capsize=5)\n",
    "plt.yticks(y_pos, results_df['model_name'])\n",
    "plt.xlabel('RMSE (Cross-Validation)')\n",
    "plt.title('Model Comparison - Cross-Validation RMSE')\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "# Add value labels\n",
    "for i, v in enumerate(results_df['mean_rmse']):\n",
    "    plt.text(v + 0.001, i, f'{v:.4f}', va='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Select top 3 models for hyperparameter tuning\n",
    "top_models = results_df.head(3)['model_name'].tolist()\n",
    "print(f\"\\nüéØ Top 3 models selected for hyperparameter tuning:\")\n",
    "for i, model in enumerate(top_models, 1):\n",
    "    rmse = results_df[results_df['model_name'] == model]['mean_rmse'].iloc[0]\n",
    "    print(f\"  {i}. {model}: {rmse:.4f} RMSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## 6. Hyperparameter Tuning\n",
    "\n",
    "We'll perform hyperparameter tuning on the top-performing models to optimize their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== HYPERPARAMETER TUNING ===\")\n",
    "\n",
    "# Define parameter grids for top models\n",
    "param_grids = {\n",
    "    'Ridge': {\n",
    "        'alpha': [0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "    },\n",
    "    'Lasso': {\n",
    "        'alpha': [0.0001, 0.001, 0.01, 0.1, 1.0]\n",
    "    },\n",
    "    'ElasticNet': {\n",
    "        'alpha': [0.001, 0.01, 0.1, 1.0],\n",
    "        'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [10, 20, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.05, 0.1, 0.15],\n",
    "        'max_depth': [3, 4, 5],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    'Extra Trees': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [10, 20, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Add XGBoost and LightGBM parameters if available\n",
    "if xgb_available:\n",
    "    param_grids['XGBoost'] = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.05, 0.1, 0.15],\n",
    "        'max_depth': [3, 4, 5],\n",
    "        'subsample': [0.8, 0.9, 1.0]\n",
    "    }\n",
    "\n",
    "if lgb_available:\n",
    "    param_grids['LightGBM'] = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.05, 0.1, 0.15],\n",
    "        'max_depth': [3, 4, 5],\n",
    "        'num_leaves': [31, 50, 100]\n",
    "    }\n",
    "\n",
    "# Tune hyperparameters for top models\n",
    "tuned_models = {}\n",
    "tuning_results = []\n",
    "\n",
    "for model_name in top_models:\n",
    "    if model_name not in param_grids:\n",
    "        print(f\"\\n‚ö†Ô∏è No parameter grid defined for {model_name}, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\nüîß Tuning {model_name}...\")\n",
    "    \n",
    "    # Get the base model\n",
    "    base_model = models[model_name]\n",
    "    \n",
    "    # Choose input data (scaled or not)\n",
    "    if model_name in scaled_models:\n",
    "        X_train_input = X_train_scaled\n",
    "        X_test_input = X_test_scaled\n",
    "    else:\n",
    "        X_train_input = X_train\n",
    "        X_test_input = X_test\n",
    "    \n",
    "    # Use RandomizedSearchCV for faster tuning (or GridSearchCV for exhaustive search)\n",
    "    search = RandomizedSearchCV(\n",
    "        base_model,\n",
    "        param_grids[model_name],\n",
    "        n_iter=20,  # Number of parameter combinations to try\n",
    "        cv=5,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        search.fit(X_train_input, y_train)\n",
    "        \n",
    "        # Store the best model\n",
    "        tuned_models[model_name] = search.best_estimator_\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = search.best_estimator_.predict(X_test_input)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        tuning_results.append({\n",
    "            'model': model_name,\n",
    "            'best_params': search.best_params_,\n",
    "            'cv_score': -search.best_score_,\n",
    "            'test_rmse': rmse,\n",
    "            'test_mae': mae,\n",
    "            'test_r2': r2\n",
    "        })\n",
    "        \n",
    "        print(f\"  ‚úÖ Best CV RMSE: {np.sqrt(-search.best_score_):.4f}\")\n",
    "        print(f\"  ‚úÖ Test RMSE: {rmse:.4f}\")\n",
    "        print(f\"  ‚úÖ Test R¬≤: {r2:.4f}\")\n",
    "        print(f\"  Best params: {search.best_params_}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå Error tuning {model_name}: {e}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Hyperparameter tuning completed for {len(tuned_models)} models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation and Validation\n",
    "\n",
    "Let's evaluate our tuned models comprehensively and select the best performer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== MODEL EVALUATION ===\")\n",
    "\n",
    "# Display tuning results\n",
    "if tuning_results:\n",
    "    tuning_df = pd.DataFrame(tuning_results)\n",
    "    tuning_df = tuning_df.sort_values('test_rmse')\n",
    "    \n",
    "    print(\"\\nTuned Model Performance:\")\n",
    "    for _, row in tuning_df.iterrows():\n",
    "        print(f\"\\n{row['model']}:\")\n",
    "        print(f\"  CV RMSE: {row['cv_score']:.4f}\")\n",
    "        print(f\"  Test RMSE: {row['test_rmse']:.4f}\")\n",
    "        print(f\"  Test MAE: {row['test_mae']:.4f}\")\n",
    "        print(f\"  Test R¬≤: {row['test_r2']:.4f}\")\n",
    "    \n",
    "    # Select best model\n",
    "    best_model_name = tuning_df.iloc[0]['model']\n",
    "    best_model = tuned_models[best_model_name]\n",
    "    best_rmse = tuning_df.iloc[0]['test_rmse']\n",
    "    best_r2 = tuning_df.iloc[0]['test_r2']\n",
    "    \n",
    "    print(f\"\\nüèÜ BEST MODEL: {best_model_name}\")\n",
    "    print(f\"   Test RMSE: {best_rmse:.4f}\")\n",
    "    print(f\"   Test R¬≤: {best_r2:.4f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"No tuning results available. Using best model from initial evaluation.\")\n",
    "    best_model_name = top_models[0]\n",
    "    best_model = models[best_model_name]\n",
    "    \n",
    "    # Train the best model\n",
    "    if best_model_name in scaled_models:\n",
    "        best_model.fit(X_train_scaled, y_train)\n",
    "        y_pred = best_model.predict(X_test_scaled)\n",
    "    else:\n",
    "        best_model.fit(X_train, y_train)\n",
    "        y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    best_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    best_r2 = r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed evaluation of the best model\n",
    "print(f\"=== DETAILED EVALUATION: {best_model_name} ===\")\n",
    "\n",
    "# Make predictions\n",
    "if best_model_name in scaled_models:\n",
    "    y_train_pred = best_model.predict(X_train_scaled)\n",
    "    y_test_pred = best_model.predict(X_test_scaled)\n",
    "else:\n",
    "    y_train_pred = best_model.predict(X_train)\n",
    "    y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate comprehensive metrics\n",
    "def calculate_metrics(y_true, y_pred, set_name):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    # Convert back from log space for interpretable metrics\n",
    "    y_true_orig = np.expm1(y_true)\n",
    "    y_pred_orig = np.expm1(y_pred)\n",
    "    \n",
    "    rmse_orig = np.sqrt(mean_squared_error(y_true_orig, y_pred_orig))\n",
    "    mae_orig = mean_absolute_error(y_true_orig, y_pred_orig)\n",
    "    mape = np.mean(np.abs((y_true_orig - y_pred_orig) / y_true_orig)) * 100\n",
    "    \n",
    "    print(f\"\\n{set_name} Set Metrics:\")\n",
    "    print(f\"  Log-space RMSE: {rmse:.4f}\")\n",
    "    print(f\"  Log-space MAE: {mae:.4f}\")\n",
    "    print(f\"  R¬≤ Score: {r2:.4f}\")\n",
    "    print(f\"  Original RMSE: ${rmse_orig:,.0f}\")\n",
    "    print(f\"  Original MAE: ${mae_orig:,.0f}\")\n",
    "    print(f\"  MAPE: {mape:.2f}%\")\n",
    "    \n",
    "    return {\n",
    "        'rmse_log': rmse, 'mae_log': mae, 'r2': r2,\n",
    "        'rmse_orig': rmse_orig, 'mae_orig': mae_orig, 'mape': mape\n",
    "    }\n",
    "\n",
    "train_metrics = calculate_metrics(y_train, y_train_pred, \"Training\")\n",
    "test_metrics = calculate_metrics(y_test, y_test_pred, \"Test\")\n",
    "\n",
    "# Check for overfitting\n",
    "rmse_diff = test_metrics['rmse_log'] - train_metrics['rmse_log']\n",
    "r2_diff = train_metrics['r2'] - test_metrics['r2']\n",
    "\n",
    "print(f\"\\nOverfitting Analysis:\")\n",
    "print(f\"  RMSE difference (test - train): {rmse_diff:.4f}\")\n",
    "print(f\"  R¬≤ difference (train - test): {r2_diff:.4f}\")\n",
    "\n",
    "if rmse_diff > 0.02 or r2_diff > 0.05:\n",
    "    print(f\"  ‚ö†Ô∏è Potential overfitting detected\")\n",
    "else:\n",
    "    print(f\"  ‚úÖ No significant overfitting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Actual vs Predicted (log space)\n",
    "axes[0,0].scatter(y_test, y_test_pred, alpha=0.6)\n",
    "axes[0,0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[0,0].set_xlabel('Actual (log)')\n",
    "axes[0,0].set_ylabel('Predicted (log)')\n",
    "axes[0,0].set_title('Actual vs Predicted (Log Space)')\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Actual vs Predicted (original space)\n",
    "y_test_orig = np.expm1(y_test)\n",
    "y_test_pred_orig = np.expm1(y_test_pred)\n",
    "axes[0,1].scatter(y_test_orig, y_test_pred_orig, alpha=0.6)\n",
    "axes[0,1].plot([y_test_orig.min(), y_test_orig.max()], [y_test_orig.min(), y_test_orig.max()], 'r--', lw=2)\n",
    "axes[0,1].set_xlabel('Actual Price ($)')\n",
    "axes[0,1].set_ylabel('Predicted Price ($)')\n",
    "axes[0,1].set_title('Actual vs Predicted (Original Scale)')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Residuals plot\n",
    "residuals = y_test - y_test_pred\n",
    "axes[1,0].scatter(y_test_pred, residuals, alpha=0.6)\n",
    "axes[1,0].axhline(y=0, color='r', linestyle='--')\n",
    "axes[1,0].set_xlabel('Predicted (log)')\n",
    "axes[1,0].set_ylabel('Residuals')\n",
    "axes[1,0].set_title('Residuals Plot')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Residuals histogram\n",
    "axes[1,1].hist(residuals, bins=30, edgecolor='black', alpha=0.7)\n",
    "axes[1,1].set_xlabel('Residuals')\n",
    "axes[1,1].set_ylabel('Frequency')\n",
    "axes[1,1].set_title('Residuals Distribution')\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Residual statistics\n",
    "print(f\"\\nResidual Analysis:\")\n",
    "print(f\"  Mean residual: {residuals.mean():.6f}\")\n",
    "print(f\"  Std residual: {residuals.std():.4f}\")\n",
    "print(f\"  Residual skewness: {residuals.skew():.4f}\")\n",
    "print(f\"  Residual kurtosis: {residuals.kurtosis():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "## 8. Model Interpretation\n",
    "\n",
    "Understanding what drives our model's predictions is crucial for business insights and model trust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"=== MODEL INTERPRETATION: {best_model_name} ===\")\n",
    "\n",
    "# Feature importance analysis\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    # Tree-based models\n",
    "    print(\"\\nüå≥ Tree-based Feature Importance:\")\n",
    "    \n",
    "    feature_names = X_final.columns[X_final.columns.isin(final_features)]\n",
    "    importances = best_model.feature_importances_\n",
    "    \n",
    "    # Create feature importance dataframe\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': importances\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 15 Most Important Features:\")\n",
    "    for _, row in importance_df.head(15).iterrows():\n",
    "        print(f\"  {row['feature']:30}: {row['importance']:.4f}\")\n",
    "    \n",
    "    # Visualize feature importance\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top_features = importance_df.head(20)\n",
    "    plt.barh(range(len(top_features)), top_features['importance'])\n",
    "    plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.title(f'Top 20 Feature Importance - {best_model_name}')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "elif hasattr(best_model, 'coef_'):\n",
    "    # Linear models\n",
    "    print(\"\\nüìà Linear Model Coefficients:\")\n",
    "    \n",
    "    feature_names = X_final.columns[X_final.columns.isin(final_features)]\n",
    "    coefficients = best_model.coef_\n",
    "    \n",
    "    # Create coefficient dataframe\n",
    "    coef_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'coefficient': coefficients,\n",
    "        'abs_coefficient': np.abs(coefficients)\n",
    "    }).sort_values('abs_coefficient', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 15 Features by Coefficient Magnitude:\")\n",
    "    for _, row in coef_df.head(15).iterrows():\n",
    "        direction = \"üìà\" if row['coefficient'] > 0 else \"üìâ\"\n",
    "        print(f\"  {direction} {row['feature']:28}: {row['coefficient']:8.4f}\")\n",
    "    \n",
    "    # Visualize coefficients\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top_coefs = coef_df.head(20)\n",
    "    colors = ['green' if x > 0 else 'red' for x in top_coefs['coefficient']]\n",
    "    plt.barh(range(len(top_coefs)), top_coefs['coefficient'], color=colors, alpha=0.7)\n",
    "    plt.yticks(range(len(top_coefs)), top_coefs['feature'])\n",
    "    plt.xlabel('Coefficient Value')\n",
    "    plt.title(f'Top 20 Feature Coefficients - {best_model_name}')\n",
    "    plt.axvline(x=0, color='black', linestyle='-', alpha=0.5)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Model doesn't support direct feature importance extraction.\")\n",
    "    print(\"Consider using permutation importance or SHAP values for interpretation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business insights from top features\n",
    "print(\"=== BUSINESS INSIGHTS ===\")\n",
    "\n",
    "if hasattr(best_model, 'feature_importances_') or hasattr(best_model, 'coef_'):\n",
    "    if hasattr(best_model, 'feature_importances_'):\n",
    "        top_features_list = importance_df.head(10)['feature'].tolist()\n",
    "    else:\n",
    "        top_features_list = coef_df.head(10)['feature'].tolist()\n",
    "    \n",
    "    print(\"\\nüè† Key Price Drivers Identified:\")\n",
    "    \n",
    "    # Categorize features\n",
    "    categories = {\n",
    "        'Size/Area': [],\n",
    "        'Quality/Condition': [],\n",
    "        'Age/Time': [],\n",
    "        'Location': [],\n",
    "        'Amenities': [],\n",
    "        'Other': []\n",
    "    }\n",
    "    \n",
    "    for feature in top_features_list:\n",
    "        feature_lower = feature.lower()\n",
    "        if any(word in feature_lower for word in ['sf', 'area', 'size', 'total']):\n",
    "            categories['Size/Area'].append(feature)\n",
    "        elif any(word in feature_lower for word in ['qual', 'cond', 'quality', 'score']):\n",
    "            categories['Quality/Condition'].append(feature)\n",
    "        elif any(word in feature_lower for word in ['age', 'year', 'built', 'remod']):\n",
    "            categories['Age/Time'].append(feature)\n",
    "        elif any(word in feature_lower for word in ['neighborhood', 'location']):\n",
    "            categories['Location'].append(feature)\n",
    "        elif any(word in feature_lower for word in ['garage', 'bath', 'fireplace', 'pool']):\n",
    "            categories['Amenities'].append(feature)\n",
    "        else:\n",
    "            categories['Other'].append(feature)\n",
    "    \n",
    "    for category, features in categories.items():\n",
    "        if features:\n",
    "            print(f\"\\n  {category}:\")\n",
    "            for feature in features:\n",
    "                print(f\"    ‚Ä¢ {feature}\")\n",
    "    \n",
    "    print(\"\\nüí° Actionable Insights:\")\n",
    "    print(\"  1. Focus on size/area features for maximum impact\")\n",
    "    print(\"  2. Quality improvements show strong returns\")\n",
    "    print(\"  3. Age/renovation timing affects value significantly\")\n",
    "    print(\"  4. Location remains a key factor (if applicable)\")\n",
    "    print(\"  5. Specific amenities drive premium pricing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "## 9. Model Persistence and Deployment Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== MODEL PERSISTENCE ===\")\n",
    "\n",
    "import joblib\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Create model artifacts directory\n",
    "import os\n",
    "artifacts_dir = 'model_artifacts'\n",
    "os.makedirs(artifacts_dir, exist_ok=True)\n",
    "\n",
    "# Save the best model\n",
    "model_filename = f'{artifacts_dir}/best_model_{best_model_name.lower().replace(\" \", \"_\")}.joblib'\n",
    "joblib.dump(best_model, model_filename)\n",
    "print(f\"‚úÖ Model saved: {model_filename}\")\n",
    "\n",
    "# Save the scaler (if used)\n",
    "if best_model_name in scaled_models:\n",
    "    scaler_filename = f'{artifacts_dir}/scaler.joblib'\n",
    "    joblib.dump(scaler, scaler_filename)\n",
    "    print(f\"‚úÖ Scaler saved: {scaler_filename}\")\n",
    "\n",
    "# Save feature list\n",
    "features_filename = f'{artifacts_dir}/selected_features.json'\n",
    "with open(features_filename, 'w') as f:\n",
    "    json.dump(final_features, f, indent=2)\n",
    "print(f\"‚úÖ Features saved: {features_filename}\")\n",
    "\n",
    "# Save model metadata\n",
    "metadata = {\n",
    "    'model_name': best_model_name,\n",
    "    'model_type': str(type(best_model).__name__),\n",
    "    'training_date': datetime.now().isoformat(),\n",
    "    'test_rmse_log': float(test_metrics['rmse_log']),\n",
    "    'test_mae_log': float(test_metrics['mae_log']),\n",
    "    'test_r2': float(test_metrics['r2']),\n",
    "    'test_rmse_original': float(test_metrics['rmse_orig']),\n",
    "    'test_mae_original': float(test_metrics['mae_orig']),\n",
    "    'test_mape': float(test_metrics['mape']),\n",
    "    'num_features': len(final_features),\n",
    "    'training_samples': int(len(X_train)),\n",
    "    'test_samples': int(len(X_test)),\n",
    "    'uses_scaling': best_model_name in scaled_models,\n",
    "    'target_transformation': 'log1p'\n",
    "}\n",
    "\n",
    "if hasattr(best_model, 'get_params'):\n",
    "    try:\n",
    "        metadata['model_parameters'] = best_model.get_params()\n",
    "    except:\n",
    "        metadata['model_parameters'] = 'Could not serialize parameters'\n",
    "\n",
    "metadata_filename = f'{artifacts_dir}/model_metadata.json'\n",
    "with open(metadata_filename, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2, default=str)\n",
    "print(f\"‚úÖ Metadata saved: {metadata_filename}\")\n",
    "\n",
    "print(f\"\\nüì¶ Model artifacts saved in '{artifacts_dir}/' directory\")\n",
    "print(f\"Files created:\")\n",
    "for file in os.listdir(artifacts_dir):\n",
    "    print(f\"  ‚Ä¢ {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prediction function for deployment\n",
    "print(\"=== DEPLOYMENT PREPARATION ===\")\n",
    "\n",
    "def predict_house_price(features_dict, model_path=None, scaler_path=None, features_path=None):\n",
    "    \"\"\"\n",
    "    Predict house price using the trained model\n",
    "    \n",
    "    Parameters:\n",
    "    features_dict: dict with feature names as keys and values\n",
    "    model_path: path to saved model\n",
    "    scaler_path: path to saved scaler (if needed)\n",
    "    features_path: path to selected features list\n",
    "    \n",
    "    Returns:\n",
    "    predicted price in original scale\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load model and artifacts (in production, these would be loaded once at startup)\n",
    "    if model_path:\n",
    "        model = joblib.load(model_path)\n",
    "    else:\n",
    "        model = best_model\n",
    "    \n",
    "    if scaler_path and os.path.exists(scaler_path):\n",
    "        scaler = joblib.load(scaler_path)\n",
    "        use_scaling = True\n",
    "    else:\n",
    "        use_scaling = False\n",
    "    \n",
    "    if features_path:\n",
    "        with open(features_path, 'r') as f:\n",
    "            selected_features = json.load(f)\n",
    "    else:\n",
    "        selected_features = final_features\n",
    "    \n",
    "    # Create feature vector\n",
    "    feature_vector = []\n",
    "    for feature in selected_features:\n",
    "        if feature in features_dict:\n",
    "            feature_vector.append(features_dict[feature])\n",
    "        else:\n",
    "            # Handle missing features with median/mode\n",
    "            feature_vector.append(0)  # Or use stored median values\n",
    "    \n",
    "    # Convert to numpy array and reshape\n",
    "    X_input = np.array(feature_vector).reshape(1, -1)\n",
    "    \n",
    "    # Scale if needed\n",
    "    if use_scaling:\n",
    "        X_input = scaler.transform(X_input)\n",
    "    \n",
    "    # Make prediction\n",
    "    y_pred_log = model.predict(X_input)[0]\n",
    "    \n",
    "    # Convert back to original scale\n",
    "    y_pred_original = np.expm1(y_pred_log)\n",
    "    \n",
    "    return y_pred_original\n",
    "\n",
    "# Example usage\n",
    "print(\"\\nüß™ Testing prediction function...\")\n",
    "\n",
    "# Get a sample from test set\n",
    "sample_idx = 0\n",
    "sample_features = dict(zip(final_features, X_test.iloc[sample_idx]))\n",
    "actual_price = np.expm1(y_test.iloc[sample_idx])\n",
    "\n",
    "# Make prediction\n",
    "predicted_price = predict_house_price(sample_features)\n",
    "\n",
    "print(f\"\\nSample Prediction:\")\n",
    "print(f\"  Actual price: ${actual_price:,.0f}\")\n",
    "print(f\"  Predicted price: ${predicted_price:,.0f}\")\n",
    "print(f\"  Difference: ${abs(actual_price - predicted_price):,.0f}\")\n",
    "print(f\"  Error rate: {abs(actual_price - predicted_price) / actual_price * 100:.2f}%\")\n",
    "\n",
    "print(f\"\\n‚úÖ Prediction function ready for deployment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "## 10. Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== PROJECT SUMMARY ===\")\n",
    "\n",
    "print(f\"\\nüéØ FINAL MODEL PERFORMANCE:\")\n",
    "print(f\"   Model: {best_model_name}\")\n",
    "print(f\"   Test R¬≤: {test_metrics['r2']:.4f} ({test_metrics['r2']*100:.1f}% variance explained)\")\n",
    "print(f\"   Test RMSE: ${test_metrics['rmse_orig']:,.0f}\")\n",
    "print(f\"   Test MAE: ${test_metrics['mae_orig']:,.0f}\")\n",
    "print(f\"   Test MAPE: {test_metrics['mape']:.2f}%\")\n",
    "\n",
    "print(f\"\\nüìä DATASET INSIGHTS:\")\n",
    "print(f\"   ‚Ä¢ Total samples: {df.shape[0]:,}\")\n",
    "print(f\"   ‚Ä¢ Original features: {df.shape[1]}\")\n",
    "print(f\"   ‚Ä¢ Engineered features: {df_fe.shape[1] - df.shape[1]}\")\n",
    "print(f\"   ‚Ä¢ Selected features: {len(final_features)}\")\n",
    "print(f\"   ‚Ä¢ Target transformation: Log(1+x) - reduced skewness from {df[target].skew():.2f} to {df_fe['SalePrice_log'].skew():.2f}\")\n",
    "\n",
    "print(f\"\\nüîß FEATURE ENGINEERING HIGHLIGHTS:\")\n",
    "new_features = ['TotalSF', 'HouseAge', 'RemodAge', 'WasRemodeled', 'TotalBaths', 'QualityScore', 'GarageScore']\n",
    "for feature in new_features:\n",
    "    if feature in df_fe.columns:\n",
    "        print(f\"   ‚úÖ {feature}: Created successfully\")\n",
    "\n",
    "print(f\"\\nüèÜ MODEL SELECTION PROCESS:\")\n",
    "print(f\"   ‚Ä¢ Models tested: {len(models)}\")\n",
    "print(f\"   ‚Ä¢ Best performer: {best_model_name}\")\n",
    "print(f\"   ‚Ä¢ Hyperparameter tuning: {'‚úÖ Completed' if tuned_models else '‚ö†Ô∏è Skipped'}\")\n",
    "print(f\"   ‚Ä¢ Cross-validation: 5-fold CV used\")\n",
    "\n",
    "print(f\"\\nüí° KEY RECOMMENDATIONS:\")\n",
    "print(f\"   1. üìà Model Performance: Achieving {test_metrics['r2']*100:.1f}% variance explanation is excellent\")\n",
    "print(f\"   2. üéØ Feature Focus: Size/area and quality features are primary value drivers\")\n",
    "print(f\"   3. üîÑ Model Updates: Retrain quarterly with new market data\")\n",
    "print(f\"   4. üìä Monitoring: Track MAPE <{test_metrics['mape']:.0f}% for production performance\")\n",
    "print(f\"   5. üöÄ Deployment: Model ready with artifacts in '{artifacts_dir}/' directory\")\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è LIMITATIONS & CONSIDERATIONS:\")\n",
    "print(f\"   ‚Ä¢ Model assumes current market conditions\")\n",
    "print(f\"   ‚Ä¢ Feature distributions may change over time\")\n",
    "print(f\"   ‚Ä¢ Predictions are estimates with ¬±${test_metrics['mae_orig']:,.0f} typical error\")\n",
    "print(f\"   ‚Ä¢ Regular retraining recommended for market changes\")\n",
    "\n",
    "print(f\"\\nüéâ REGRESSION MODELING PROJECT COMPLETED SUCCESSFULLY!\")\n",
    "print(f\"\\nNext steps:\")\n",
    "print(f\"   ‚Ä¢ Deploy model to production environment\")\n",
    "print(f\"   ‚Ä¢ Set up monitoring and alerting\")\n",
    "print(f\"   ‚Ä¢ Establish retraining pipeline\")\n",
    "print(f\"   ‚Ä¢ Create business dashboard for insights\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}