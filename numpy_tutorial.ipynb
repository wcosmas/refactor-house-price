{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NumPy Tutorial: Complete Guide for Numerical Computing\n",
    "\n",
    "This notebook provides a comprehensive introduction to NumPy, the fundamental package for scientific computing in Python.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Introduction to NumPy](#introduction)\n",
    "2. [NumPy Arrays: Creation and Properties](#arrays)\n",
    "3. [Array Indexing and Slicing](#indexing)\n",
    "4. [Array Reshaping and Manipulation](#reshaping)\n",
    "5. [Mathematical Operations](#math-operations)\n",
    "6. [Broadcasting](#broadcasting)\n",
    "7. [Statistical Operations](#statistics)\n",
    "8. [Linear Algebra](#linear-algebra)\n",
    "9. [Random Number Generation](#random)\n",
    "10. [File I/O](#file-io)\n",
    "11. [Performance and Memory](#performance)\n",
    "12. [Real-world Applications](#applications)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to NumPy {#introduction}\n",
    "\n",
    "NumPy (Numerical Python) is the core library for scientific computing in Python. It provides:\n",
    "- A powerful N-dimensional array object (ndarray)\n",
    "- Sophisticated broadcasting functions\n",
    "- Tools for integrating C/C++ and Fortran code\n",
    "- Useful linear algebra, Fourier transform, and random number capabilities\n",
    "\n",
    "### Why NumPy?\n",
    "- **Performance**: Operations are implemented in C and are much faster than pure Python\n",
    "- **Memory Efficient**: Arrays use less memory than Python lists\n",
    "- **Vectorization**: Perform operations on entire arrays without writing loops\n",
    "- **Broadcasting**: Perform operations on arrays of different shapes\n",
    "\n",
    "Let's start by importing NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version: 1.24.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "\n",
    "# Set print options for better display\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. NumPy Arrays: Creation and Properties {#arrays}\n",
    "\n",
    "### Creating Arrays\n",
    "NumPy arrays are the central data structure. Let's explore different ways to create them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1D Array from list:\n",
      "Array: [1 2 3 4 5]\n",
      "Type: <class 'numpy.ndarray'>\n",
      "Data type: int64\n",
      "Shape: (5,)\n",
      "Size: 5\n",
      "Dimensions: 1\n",
      "\n",
      "2D Array from nested list:\n",
      "Array:\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "Shape: (3, 3)\n",
      "Size: 9\n",
      "Dimensions: 2\n",
      "\n",
      "3D Array:\n",
      "Array:\n",
      "[[[1 2]\n",
      "  [3 4]]\n",
      "\n",
      " [[5 6]\n",
      "  [7 8]]]\n",
      "Shape: (2, 2, 2)\n",
      "Dimensions: 3\n"
     ]
    }
   ],
   "source": [
    "# Creating arrays from Python lists\n",
    "print(\"1D Array from list:\")\n",
    "arr_1d = np.array([1, 2, 3, 4, 5])\n",
    "print(f\"Array: {arr_1d}\")\n",
    "print(f\"Type: {type(arr_1d)}\")\n",
    "print(f\"Data type: {arr_1d.dtype}\")\n",
    "print(f\"Shape: {arr_1d.shape}\")\n",
    "print(f\"Size: {arr_1d.size}\")\n",
    "print(f\"Dimensions: {arr_1d.ndim}\")\n",
    "print()\n",
    "\n",
    "# 2D array\n",
    "print(\"2D Array from nested list:\")\n",
    "arr_2d = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(f\"Array:\\n{arr_2d}\")\n",
    "print(f\"Shape: {arr_2d.shape}\")\n",
    "print(f\"Size: {arr_2d.size}\")\n",
    "print(f\"Dimensions: {arr_2d.ndim}\")\n",
    "print()\n",
    "\n",
    "# 3D array\n",
    "print(\"3D Array:\")\n",
    "arr_3d = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
    "print(f\"Array:\\n{arr_3d}\")\n",
    "print(f\"Shape: {arr_3d.shape}\")\n",
    "print(f\"Dimensions: {arr_3d.ndim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrays with specific data types:\n",
      "Integer array: [1 2 3 4], dtype: int32\n",
      "Float array: [1. 2. 3. 4.], dtype: float64\n",
      "Complex array: [1.+2.j 3.+4.j], dtype: complex128\n",
      "Boolean array: [ True False  True], dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# Specifying data types\n",
    "print(\"Arrays with specific data types:\")\n",
    "\n",
    "# Integer array\n",
    "int_array = np.array([1, 2, 3, 4], dtype=np.int32)\n",
    "print(f\"Integer array: {int_array}, dtype: {int_array.dtype}\")\n",
    "\n",
    "# Float array\n",
    "float_array = np.array([1, 2, 3, 4], dtype=np.float64)\n",
    "print(f\"Float array: {float_array}, dtype: {float_array.dtype}\")\n",
    "\n",
    "# Complex array\n",
    "complex_array = np.array([1+2j, 3+4j], dtype=np.complex128)\n",
    "print(f\"Complex array: {complex_array}, dtype: {complex_array.dtype}\")\n",
    "\n",
    "# Boolean array\n",
    "bool_array = np.array([True, False, True], dtype=bool)\n",
    "print(f\"Boolean array: {bool_array}, dtype: {bool_array.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array creation functions\n",
    "print(\"Array creation functions:\\n\")\n",
    "\n",
    "# Zeros\n",
    "zeros_array = np.zeros((3, 4))\n",
    "print(f\"Zeros array:\\n{zeros_array}\\n\")\n",
    "\n",
    "# Ones\n",
    "ones_array = np.ones((2, 3, 2))\n",
    "print(f\"Ones array shape: {ones_array.shape}\")\n",
    "print(f\"First slice:\\n{ones_array[0]}\\n\")\n",
    "\n",
    "# Full (filled with a specific value)\n",
    "full_array = np.full((2, 3), 7)\n",
    "print(f\"Array filled with 7:\\n{full_array}\\n\")\n",
    "\n",
    "# Identity matrix\n",
    "identity = np.eye(4)\n",
    "print(f\"Identity matrix:\\n{identity}\\n\")\n",
    "\n",
    "# Empty array (uninitialized)\n",
    "empty_array = np.empty((2, 2))\n",
    "print(f\"Empty array (values are random):\\n{empty_array}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Range-based array creation\n",
    "print(\"Range-based arrays:\\n\")\n",
    "\n",
    "# arange - similar to Python's range\n",
    "arange_array = np.arange(0, 10, 2)\n",
    "print(f\"arange(0, 10, 2): {arange_array}\")\n",
    "\n",
    "# linspace - linearly spaced values\n",
    "linspace_array = np.linspace(0, 1, 11)\n",
    "print(f\"linspace(0, 1, 11): {linspace_array}\")\n",
    "\n",
    "# logspace - logarithmically spaced values\n",
    "logspace_array = np.logspace(0, 2, 5)\n",
    "print(f\"logspace(0, 2, 5): {logspace_array}\")\n",
    "\n",
    "# meshgrid - create coordinate arrays\n",
    "x = np.linspace(-2, 2, 5)\n",
    "y = np.linspace(-1, 1, 3)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "print(f\"\\nMeshgrid X:\\n{X}\")\n",
    "print(f\"Meshgrid Y:\\n{Y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Array Indexing and Slicing {#indexing}\n",
    "\n",
    "NumPy arrays support sophisticated indexing and slicing operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic indexing\n",
    "arr = np.array([10, 20, 30, 40, 50])\n",
    "print(\"1D Array indexing:\")\n",
    "print(f\"Array: {arr}\")\n",
    "print(f\"First element: {arr[0]}\")\n",
    "print(f\"Last element: {arr[-1]}\")\n",
    "print(f\"Slice [1:4]: {arr[1:4]}\")\n",
    "print(f\"Every 2nd element: {arr[::2]}\")\n",
    "print(f\"Reverse array: {arr[::-1]}\")\n",
    "print()\n",
    "\n",
    "# 2D array indexing\n",
    "arr_2d = np.array([[1, 2, 3, 4],\n",
    "                   [5, 6, 7, 8],\n",
    "                   [9, 10, 11, 12]])\n",
    "print(\"2D Array indexing:\")\n",
    "print(f\"Array:\\n{arr_2d}\")\n",
    "print(f\"Element at [1, 2]: {arr_2d[1, 2]}\")\n",
    "print(f\"First row: {arr_2d[0]}\")\n",
    "print(f\"Second column: {arr_2d[:, 1]}\")\n",
    "print(f\"Subarray [0:2, 1:3]:\\n{arr_2d[0:2, 1:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean indexing\n",
    "arr = np.array([1, 5, 3, 8, 2, 9, 4])\n",
    "print(\"Boolean indexing:\")\n",
    "print(f\"Original array: {arr}\")\n",
    "\n",
    "# Create boolean mask\n",
    "mask = arr > 4\n",
    "print(f\"Mask (arr > 4): {mask}\")\n",
    "print(f\"Elements > 4: {arr[mask]}\")\n",
    "print(f\"Direct boolean indexing: {arr[arr > 4]}\")\n",
    "\n",
    "# Multiple conditions\n",
    "print(f\"Elements between 3 and 7: {arr[(arr >= 3) & (arr <= 7)]}\")\n",
    "print(f\"Elements < 3 or > 7: {arr[(arr < 3) | (arr > 7)]}\")\n",
    "print()\n",
    "\n",
    "# Boolean indexing with 2D arrays\n",
    "arr_2d = np.array([[1, 2, 3],\n",
    "                   [4, 5, 6],\n",
    "                   [7, 8, 9]])\n",
    "print(\"2D Boolean indexing:\")\n",
    "print(f\"Array:\\n{arr_2d}\")\n",
    "print(f\"Elements > 5: {arr_2d[arr_2d > 5]}\")\n",
    "print(f\"Rows where first element > 3:\\n{arr_2d[arr_2d[:, 0] > 3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fancy indexing (using arrays as indices)\n",
    "arr = np.array([10, 20, 30, 40, 50])\n",
    "indices = np.array([0, 2, 4])\n",
    "print(\"Fancy indexing:\")\n",
    "print(f\"Array: {arr}\")\n",
    "print(f\"Indices: {indices}\")\n",
    "print(f\"Elements at indices: {arr[indices]}\")\n",
    "print()\n",
    "\n",
    "# 2D fancy indexing\n",
    "arr_2d = np.arange(12).reshape(3, 4)\n",
    "print(f\"2D Array:\\n{arr_2d}\")\n",
    "\n",
    "# Select specific rows\n",
    "rows = np.array([0, 2])\n",
    "print(f\"Selected rows [0, 2]:\\n{arr_2d[rows]}\")\n",
    "\n",
    "# Select specific elements\n",
    "row_indices = np.array([0, 1, 2])\n",
    "col_indices = np.array([0, 1, 2])\n",
    "print(f\"Diagonal elements: {arr_2d[row_indices, col_indices]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Array Reshaping and Manipulation {#reshaping}\n",
    "\n",
    "NumPy provides powerful tools for changing array shapes and manipulating array structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping arrays\n",
    "arr = np.arange(12)\n",
    "print(\"Reshaping arrays:\")\n",
    "print(f\"Original array: {arr}\")\n",
    "print(f\"Shape: {arr.shape}\")\n",
    "print()\n",
    "\n",
    "# Reshape to 2D\n",
    "arr_2d = arr.reshape(3, 4)\n",
    "print(f\"Reshaped to (3, 4):\\n{arr_2d}\")\n",
    "print()\n",
    "\n",
    "# Reshape to 3D\n",
    "arr_3d = arr.reshape(2, 3, 2)\n",
    "print(f\"Reshaped to (2, 3, 2):\\n{arr_3d}\")\n",
    "print()\n",
    "\n",
    "# Use -1 for automatic dimension calculation\n",
    "auto_reshape = arr.reshape(4, -1)\n",
    "print(f\"Reshape with auto dimension (4, -1):\\n{auto_reshape}\")\n",
    "print()\n",
    "\n",
    "# Flatten array\n",
    "flattened = arr_2d.flatten()\n",
    "print(f\"Flattened: {flattened}\")\n",
    "\n",
    "# Ravel (returns view when possible)\n",
    "raveled = arr_2d.ravel()\n",
    "print(f\"Raveled: {raveled}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding and removing dimensions\n",
    "arr = np.array([1, 2, 3, 4])\n",
    "print(\"Dimension manipulation:\")\n",
    "print(f\"Original: {arr}, shape: {arr.shape}\")\n",
    "\n",
    "# Add new axis\n",
    "arr_col = arr[:, np.newaxis]\n",
    "print(f\"Column vector:\\n{arr_col}, shape: {arr_col.shape}\")\n",
    "\n",
    "arr_row = arr[np.newaxis, :]\n",
    "print(f\"Row vector: {arr_row}, shape: {arr_row.shape}\")\n",
    "\n",
    "# Using expand_dims\n",
    "expanded = np.expand_dims(arr, axis=0)\n",
    "print(f\"Expanded: {expanded}, shape: {expanded.shape}\")\n",
    "\n",
    "# Remove single-dimensional entries\n",
    "squeezed = np.squeeze(expanded)\n",
    "print(f\"Squeezed: {squeezed}, shape: {squeezed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array concatenation and splitting\n",
    "arr1 = np.array([1, 2, 3])\n",
    "arr2 = np.array([4, 5, 6])\n",
    "\n",
    "print(\"Array concatenation:\")\n",
    "print(f\"Array 1: {arr1}\")\n",
    "print(f\"Array 2: {arr2}\")\n",
    "\n",
    "# Concatenate along axis 0 (default)\n",
    "concatenated = np.concatenate([arr1, arr2])\n",
    "print(f\"Concatenated: {concatenated}\")\n",
    "\n",
    "# Stack arrays\n",
    "stacked_v = np.vstack([arr1, arr2])\n",
    "print(f\"Vertically stacked:\\n{stacked_v}\")\n",
    "\n",
    "stacked_h = np.hstack([arr1, arr2])\n",
    "print(f\"Horizontally stacked: {stacked_h}\")\n",
    "print()\n",
    "\n",
    "# 2D array operations\n",
    "arr_2d_1 = np.array([[1, 2], [3, 4]])\n",
    "arr_2d_2 = np.array([[5, 6], [7, 8]])\n",
    "\n",
    "print(\"2D array operations:\")\n",
    "print(f\"Array 1:\\n{arr_2d_1}\")\n",
    "print(f\"Array 2:\\n{arr_2d_2}\")\n",
    "\n",
    "# Concatenate along different axes\n",
    "concat_axis0 = np.concatenate([arr_2d_1, arr_2d_2], axis=0)\n",
    "print(f\"Concatenated along axis 0:\\n{concat_axis0}\")\n",
    "\n",
    "concat_axis1 = np.concatenate([arr_2d_1, arr_2d_2], axis=1)\n",
    "print(f\"Concatenated along axis 1:\\n{concat_axis1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array splitting\n",
    "arr = np.arange(12)\n",
    "print(\"Array splitting:\")\n",
    "print(f\"Original array: {arr}\")\n",
    "\n",
    "# Split into equal parts\n",
    "split_equal = np.split(arr, 3)\n",
    "print(f\"Split into 3 equal parts: {split_equal}\")\n",
    "\n",
    "# Split at specific indices\n",
    "split_indices = np.split(arr, [3, 8])\n",
    "print(f\"Split at indices [3, 8]: {split_indices}\")\n",
    "print()\n",
    "\n",
    "# 2D array splitting\n",
    "arr_2d = np.arange(12).reshape(4, 3)\n",
    "print(f\"2D array:\\n{arr_2d}\")\n",
    "\n",
    "# Horizontal split\n",
    "hsplit_result = np.hsplit(arr_2d, 3)\n",
    "print(f\"Horizontal split: {len(hsplit_result)} arrays\")\n",
    "for i, sub_arr in enumerate(hsplit_result):\n",
    "    print(f\"  Part {i}:\\n{sub_arr}\")\n",
    "\n",
    "# Vertical split\n",
    "vsplit_result = np.vsplit(arr_2d, 2)\n",
    "print(f\"\\nVertical split: {len(vsplit_result)} arrays\")\n",
    "for i, sub_arr in enumerate(vsplit_result):\n",
    "    print(f\"  Part {i}:\\n{sub_arr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Mathematical Operations {#math-operations}\n",
    "\n",
    "NumPy provides a comprehensive set of mathematical functions that operate element-wise on arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic arithmetic operations\n",
    "arr1 = np.array([1, 2, 3, 4])\n",
    "arr2 = np.array([10, 20, 30, 40])\n",
    "\n",
    "print(\"Basic arithmetic operations:\")\n",
    "print(f\"Array 1: {arr1}\")\n",
    "print(f\"Array 2: {arr2}\")\n",
    "print()\n",
    "\n",
    "# Element-wise operations\n",
    "print(f\"Addition: {arr1 + arr2}\")\n",
    "print(f\"Subtraction: {arr2 - arr1}\")\n",
    "print(f\"Multiplication: {arr1 * arr2}\")\n",
    "print(f\"Division: {arr2 / arr1}\")\n",
    "print(f\"Power: {arr1 ** 2}\")\n",
    "print(f\"Modulo: {arr2 % arr1}\")\n",
    "print()\n",
    "\n",
    "# Operations with scalars\n",
    "print(\"Operations with scalars:\")\n",
    "print(f\"Add 10: {arr1 + 10}\")\n",
    "print(f\"Multiply by 2: {arr1 * 2}\")\n",
    "print(f\"Square: {arr1 ** 2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mathematical functions\n",
    "arr = np.array([0, np.pi/4, np.pi/2, np.pi, 2*np.pi])\n",
    "\n",
    "print(\"Mathematical functions:\")\n",
    "print(f\"Array (in radians): {arr}\")\n",
    "print()\n",
    "\n",
    "# Trigonometric functions\n",
    "print(\"Trigonometric functions:\")\n",
    "print(f\"sin: {np.sin(arr)}\")\n",
    "print(f\"cos: {np.cos(arr)}\")\n",
    "print(f\"tan: {np.tan(arr[:3])}\")\n",
    "print()\n",
    "\n",
    "# Exponential and logarithmic functions\n",
    "positive_arr = np.array([1, 2, 4, 8, 16])\n",
    "print(\"Exponential and logarithmic functions:\")\n",
    "print(f\"Array: {positive_arr}\")\n",
    "print(f\"exp: {np.exp(np.array([0, 1, 2]))}\")\n",
    "print(f\"log (natural): {np.log(positive_arr)}\")\n",
    "print(f\"log10: {np.log10(positive_arr)}\")\n",
    "print(f\"sqrt: {np.sqrt(positive_arr)}\")\n",
    "print()\n",
    "\n",
    "# Rounding functions\n",
    "decimal_arr = np.array([1.2, 2.7, -3.4, 4.9, -5.1])\n",
    "print(\"Rounding functions:\")\n",
    "print(f\"Original: {decimal_arr}\")\n",
    "print(f\"round: {np.round(decimal_arr)}\")\n",
    "print(f\"floor: {np.floor(decimal_arr)}\")\n",
    "print(f\"ceil: {np.ceil(decimal_arr)}\")\n",
    "print(f\"trunc: {np.trunc(decimal_arr)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregation functions\n",
    "arr = np.array([[1, 2, 3, 4],\n",
    "                [5, 6, 7, 8],\n",
    "                [9, 10, 11, 12]])\n",
    "\n",
    "print(\"Aggregation functions:\")\n",
    "print(f\"Array:\\n{arr}\")\n",
    "print()\n",
    "\n",
    "# Global aggregations\n",
    "print(\"Global aggregations:\")\n",
    "print(f\"Sum: {np.sum(arr)}\")\n",
    "print(f\"Mean: {np.mean(arr)}\")\n",
    "print(f\"Median: {np.median(arr)}\")\n",
    "print(f\"Standard deviation: {np.std(arr)}\")\n",
    "print(f\"Variance: {np.var(arr)}\")\n",
    "print(f\"Min: {np.min(arr)}\")\n",
    "print(f\"Max: {np.max(arr)}\")\n",
    "print()\n",
    "\n",
    "# Axis-specific aggregations\n",
    "print(\"Aggregations along axes:\")\n",
    "print(f\"Sum along axis 0 (columns): {np.sum(arr, axis=0)}\")\n",
    "print(f\"Sum along axis 1 (rows): {np.sum(arr, axis=1)}\")\n",
    "print(f\"Mean along axis 0: {np.mean(arr, axis=0)}\")\n",
    "print(f\"Max along axis 1: {np.max(arr, axis=1)}\")\n",
    "print()\n",
    "\n",
    "# Index functions\n",
    "print(\"Index functions:\")\n",
    "print(f\"Index of min element: {np.argmin(arr)}\")\n",
    "print(f\"Index of max element: {np.argmax(arr)}\")\n",
    "print(f\"Indices of min along axis 0: {np.argmin(arr, axis=0)}\")\n",
    "print(f\"Indices of max along axis 1: {np.argmax(arr, axis=1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Broadcasting {#broadcasting}\n",
    "\n",
    "Broadcasting allows NumPy to perform operations on arrays of different shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic broadcasting examples\n",
    "print(\"Broadcasting examples:\")\n",
    "\n",
    "# Scalar with array\n",
    "arr = np.array([1, 2, 3, 4])\n",
    "scalar = 10\n",
    "print(f\"Array: {arr}\")\n",
    "print(f\"Scalar: {scalar}\")\n",
    "print(f\"Array + Scalar: {arr + scalar}\")\n",
    "print()\n",
    "\n",
    "# 1D array with 2D array\n",
    "arr_1d = np.array([1, 2, 3])\n",
    "arr_2d = np.array([[10, 20, 30],\n",
    "                   [40, 50, 60]])\n",
    "\n",
    "print(f\"1D array: {arr_1d}\")\n",
    "print(f\"2D array:\\n{arr_2d}\")\n",
    "print(f\"2D + 1D:\\n{arr_2d + arr_1d}\")\n",
    "print()\n",
    "\n",
    "# Broadcasting with different shapes\n",
    "a = np.array([[1], [2], [3]])  # shape (3, 1)\n",
    "b = np.array([10, 20, 30, 40])  # shape (4,)\n",
    "\n",
    "print(f\"Array a (3,1):\\n{a}\")\n",
    "print(f\"Array b (4,): {b}\")\n",
    "print(f\"a + b (broadcasts to 3,4):\\n{a + b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Broadcasting rules visualization\n",
    "print(\"Broadcasting rules:\")\n",
    "print(\"1. Arrays are aligned from the rightmost dimension\")\n",
    "print(\"2. Dimensions of size 1 are stretched to match\")\n",
    "print(\"3. Missing dimensions are assumed to be size 1\")\n",
    "print()\n",
    "\n",
    "# Example with step-by-step explanation\n",
    "a = np.arange(6).reshape(2, 3)\n",
    "b = np.array([10, 20, 30])\n",
    "\n",
    "print(f\"Array a shape {a.shape}:\\n{a}\")\n",
    "print(f\"Array b shape {b.shape}: {b}\")\n",
    "print()\n",
    "print(\"Broadcasting process:\")\n",
    "print(f\"a: (2, 3)\")\n",
    "print(f\"b: (   3) -> (1, 3) -> (2, 3)\")\n",
    "print(f\"Result:\\n{a + b}\")\n",
    "print()\n",
    "\n",
    "# More complex example\n",
    "a = np.arange(12).reshape(3, 4, 1)\n",
    "b = np.arange(5).reshape(1, 1, 5)\n",
    "\n",
    "print(f\"Complex broadcasting:\")\n",
    "print(f\"Array a shape: {a.shape}\")\n",
    "print(f\"Array b shape: {b.shape}\")\n",
    "result = a + b\n",
    "print(f\"Result shape: {result.shape}\")\n",
    "print(f\"First slice of result:\\n{result[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practical broadcasting examples\n",
    "print(\"Practical broadcasting applications:\\n\")\n",
    "\n",
    "# Normalize each row of a 2D array\n",
    "data = np.random.randint(1, 10, size=(4, 3))\n",
    "print(f\"Original data:\\n{data}\")\n",
    "\n",
    "# Calculate row means and subtract from each row\n",
    "row_means = np.mean(data, axis=1, keepdims=True)\n",
    "print(f\"Row means:\\n{row_means}\")\n",
    "\n",
    "normalized_data = data - row_means\n",
    "print(f\"Normalized data (zero mean rows):\\n{normalized_data}\")\n",
    "print(f\"Check - row means after normalization: {np.mean(normalized_data, axis=1)}\")\n",
    "print()\n",
    "\n",
    "# Create a distance matrix\n",
    "points = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "print(f\"Points:\\n{points}\")\n",
    "\n",
    "# Calculate pairwise distances using broadcasting\n",
    "diff = points[:, np.newaxis] - points[np.newaxis, :]\n",
    "distances = np.sqrt(np.sum(diff**2, axis=2))\n",
    "print(f\"Distance matrix:\\n{distances}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Statistical Operations {#statistics}\n",
    "\n",
    "NumPy provides extensive statistical functions for data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample data\n",
    "np.random.seed(42)\n",
    "data = np.random.normal(100, 15, 1000)  # Normal distribution: mean=100, std=15\n",
    "\n",
    "print(\"Statistical measures:\")\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "print(f\"First 10 values: {data[:10]}\")\n",
    "print()\n",
    "\n",
    "# Basic statistics\n",
    "print(\"Descriptive statistics:\")\n",
    "print(f\"Mean: {np.mean(data):.3f}\")\n",
    "print(f\"Median: {np.median(data):.3f}\")\n",
    "print(f\"Standard deviation: {np.std(data):.3f}\")\n",
    "print(f\"Variance: {np.var(data):.3f}\")\n",
    "print(f\"Minimum: {np.min(data):.3f}\")\n",
    "print(f\"Maximum: {np.max(data):.3f}\")\n",
    "print(f\"Range: {np.ptp(data):.3f}\")\n",
    "print()\n",
    "\n",
    "# Percentiles and quantiles\n",
    "print(\"Percentiles and quantiles:\")\n",
    "percentiles = [25, 50, 75, 90, 95, 99]\n",
    "for p in percentiles:\n",
    "    value = np.percentile(data, p)\n",
    "    print(f\"{p}th percentile: {value:.3f}\")\n",
    "print()\n",
    "\n",
    "# Quartiles\n",
    "q1, q2, q3 = np.percentile(data, [25, 50, 75])\n",
    "iqr = q3 - q1\n",
    "print(f\"Q1 (25th): {q1:.3f}\")\n",
    "print(f\"Q2 (50th/Median): {q2:.3f}\")\n",
    "print(f\"Q3 (75th): {q3:.3f}\")\n",
    "print(f\"IQR: {iqr:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-dimensional statistics\n",
    "data_2d = np.random.randn(5, 4)\n",
    "print(\"Multi-dimensional statistics:\")\n",
    "print(f\"2D Data:\\n{data_2d}\")\n",
    "print()\n",
    "\n",
    "# Statistics along different axes\n",
    "print(\"Statistics along axes:\")\n",
    "print(f\"Mean of entire array: {np.mean(data_2d):.3f}\")\n",
    "print(f\"Mean along axis 0 (columns): {np.mean(data_2d, axis=0)}\")\n",
    "print(f\"Mean along axis 1 (rows): {np.mean(data_2d, axis=1)}\")\n",
    "print()\n",
    "print(f\"Std along axis 0: {np.std(data_2d, axis=0)}\")\n",
    "print(f\"Std along axis 1: {np.std(data_2d, axis=1)}\")\n",
    "print()\n",
    "\n",
    "# Correlation and covariance\n",
    "print(\"Correlation and covariance:\")\n",
    "# Generate correlated data\n",
    "x = np.random.randn(100)\n",
    "y = 2 * x + np.random.randn(100) * 0.5  # y is correlated with x\n",
    "z = np.random.randn(100)  # z is independent\n",
    "\n",
    "data_corr = np.column_stack([x, y, z])\n",
    "print(f\"Correlation matrix:\\n{np.corrcoef(data_corr.T)}\")\n",
    "print(f\"Covariance matrix:\\n{np.cov(data_corr.T)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram and binning\n",
    "print(\"Histogram and binning:\")\n",
    "data = np.random.exponential(2, 1000)\n",
    "\n",
    "# Calculate histogram\n",
    "counts, bin_edges = np.histogram(data, bins=10)\n",
    "print(f\"Histogram counts: {counts}\")\n",
    "print(f\"Bin edges: {bin_edges}\")\n",
    "print()\n",
    "\n",
    "# Custom bins\n",
    "custom_bins = [0, 1, 2, 5, 10, 20]\n",
    "counts_custom, _ = np.histogram(data, bins=custom_bins)\n",
    "print(f\"Custom bin counts: {counts_custom}\")\n",
    "print()\n",
    "\n",
    "# 2D histogram\n",
    "x = np.random.randn(1000)\n",
    "y = np.random.randn(1000)\n",
    "hist_2d, x_edges, y_edges = np.histogram2d(x, y, bins=5)\n",
    "print(f\"2D histogram shape: {hist_2d.shape}\")\n",
    "print(f\"2D histogram:\\n{hist_2d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Linear Algebra {#linear-algebra}\n",
    "\n",
    "NumPy provides comprehensive linear algebra functionality through the `numpy.linalg` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix operations\n",
    "A = np.array([[1, 2, 3],\n",
    "              [4, 5, 6],\n",
    "              [7, 8, 10]])\n",
    "\n",
    "B = np.array([[2, 1, 0],\n",
    "              [1, 3, 2],\n",
    "              [0, 1, 4]])\n",
    "\n",
    "print(\"Matrix operations:\")\n",
    "print(f\"Matrix A:\\n{A}\")\n",
    "print(f\"Matrix B:\\n{B}\")\n",
    "print()\n",
    "\n",
    "# Matrix multiplication\n",
    "print(\"Matrix multiplication:\")\n",
    "print(f\"A @ B (matrix multiplication):\\n{A @ B}\")\n",
    "print(f\"np.dot(A, B):\\n{np.dot(A, B)}\")\n",
    "print(f\"A * B (element-wise):\\n{A * B}\")\n",
    "print()\n",
    "\n",
    "# Transpose\n",
    "print(f\"Transpose of A:\\n{A.T}\")\n",
    "print(f\"Transpose using np.transpose:\\n{np.transpose(A)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear algebra functions\n",
    "print(\"Linear algebra functions:\\n\")\n",
    "\n",
    "# Determinant\n",
    "det_A = np.linalg.det(A)\n",
    "print(f\"Determinant of A: {det_A:.6f}\")\n",
    "\n",
    "# Inverse (if determinant != 0)\n",
    "if abs(det_A) > 1e-10:\n",
    "    A_inv = np.linalg.inv(A)\n",
    "    print(f\"Inverse of A:\\n{A_inv}\")\n",
    "    print(f\"A @ A_inv (should be identity):\\n{A @ A_inv}\")\n",
    "else:\n",
    "    print(\"Matrix A is singular (determinant ≈ 0)\")\n",
    "print()\n",
    "\n",
    "# Rank\n",
    "rank_A = np.linalg.matrix_rank(A)\n",
    "print(f\"Rank of A: {rank_A}\")\n",
    "\n",
    "# Trace\n",
    "trace_A = np.trace(A)\n",
    "print(f\"Trace of A: {trace_A}\")\n",
    "\n",
    "# Norm\n",
    "print(f\"Frobenius norm of A: {np.linalg.norm(A, 'fro'):.3f}\")\n",
    "print(f\"2-norm of A: {np.linalg.norm(A, 2):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigenvalues and eigenvectors\n",
    "print(\"Eigenvalue decomposition:\")\n",
    "eigenvalues, eigenvectors = np.linalg.eig(A)\n",
    "print(f\"Eigenvalues: {eigenvalues}\")\n",
    "print(f\"Eigenvectors:\\n{eigenvectors}\")\n",
    "print()\n",
    "\n",
    "# Verify eigenvalue equation: Av = λv\n",
    "print(\"Verification (Av = λv for first eigenvalue/eigenvector):\")\n",
    "v1 = eigenvectors[:, 0]\n",
    "lambda1 = eigenvalues[0]\n",
    "Av1 = A @ v1\n",
    "lambda_v1 = lambda1 * v1\n",
    "print(f\"Av1: {Av1}\")\n",
    "print(f\"λv1: {lambda_v1}\")\n",
    "print(f\"Difference: {np.allclose(Av1, lambda_v1)}\")\n",
    "print()\n",
    "\n",
    "# SVD (Singular Value Decomposition)\n",
    "print(\"Singular Value Decomposition:\")\n",
    "U, s, Vt = np.linalg.svd(A)\n",
    "print(f\"U shape: {U.shape}\")\n",
    "print(f\"Singular values: {s}\")\n",
    "print(f\"Vt shape: {Vt.shape}\")\n",
    "\n",
    "# Reconstruct matrix\n",
    "S = np.zeros_like(A, dtype=float)\n",
    "S[:min(A.shape), :min(A.shape)] = np.diag(s)\n",
    "A_reconstructed = U @ S @ Vt\n",
    "print(f\"Reconstruction error: {np.allclose(A, A_reconstructed)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solving linear systems\n",
    "print(\"Solving linear systems (Ax = b):\")\n",
    "\n",
    "# Create a system Ax = b\n",
    "A_system = np.array([[2, 1, -1],\n",
    "                     [-3, -1, 2],\n",
    "                     [-2, 1, 2]], dtype=float)\n",
    "b = np.array([8, -11, -3], dtype=float)\n",
    "\n",
    "print(f\"Matrix A:\\n{A_system}\")\n",
    "print(f\"Vector b: {b}\")\n",
    "print()\n",
    "\n",
    "# Solve using linalg.solve\n",
    "x = np.linalg.solve(A_system, b)\n",
    "print(f\"Solution x: {x}\")\n",
    "\n",
    "# Verify solution\n",
    "verification = A_system @ x\n",
    "print(f\"Verification (Ax): {verification}\")\n",
    "print(f\"Target (b): {b}\")\n",
    "print(f\"Solution is correct: {np.allclose(verification, b)}\")\n",
    "print()\n",
    "\n",
    "# Least squares solution for overdetermined system\n",
    "print(\"Least squares solution:\")\n",
    "A_overdetermined = np.array([[1, 1],\n",
    "                            [1, 2],\n",
    "                            [1, 3],\n",
    "                            [1, 4]], dtype=float)\n",
    "b_overdetermined = np.array([6, 8, 10, 12], dtype=float)\n",
    "\n",
    "x_lstsq, residuals, rank, s = np.linalg.lstsq(A_overdetermined, b_overdetermined, rcond=None)\n",
    "print(f\"Least squares solution: {x_lstsq}\")\n",
    "print(f\"Residuals: {residuals}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Random Number Generation {#random}\n",
    "\n",
    "NumPy provides extensive random number generation capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random number generation basics\n",
    "print(\"Random number generation:\\n\")\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Basic random functions\n",
    "print(\"Basic random functions:\")\n",
    "print(f\"Random float [0, 1): {np.random.random()}\")\n",
    "print(f\"Random integers [1, 10]: {np.random.randint(1, 11, size=5)}\")\n",
    "print(f\"Random choice from array: {np.random.choice(['A', 'B', 'C', 'D'], size=3)}\")\n",
    "print()\n",
    "\n",
    "# Random arrays\n",
    "print(\"Random arrays:\")\n",
    "random_array = np.random.random((3, 4))\n",
    "print(f\"Random 3x4 array:\\n{random_array}\")\n",
    "print()\n",
    "\n",
    "# Shuffle and permutation\n",
    "arr = np.arange(10)\n",
    "print(f\"Original array: {arr}\")\n",
    "\n",
    "# Shuffle in place\n",
    "shuffled = arr.copy()\n",
    "np.random.shuffle(shuffled)\n",
    "print(f\"Shuffled: {shuffled}\")\n",
    "\n",
    "# Permutation (returns new array)\n",
    "permuted = np.random.permutation(arr)\n",
    "print(f\"Permuted: {permuted}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random distributions\n",
    "print(\"Random distributions:\\n\")\n",
    "\n",
    "# Normal distribution\n",
    "normal_samples = np.random.normal(loc=0, scale=1, size=1000)\n",
    "print(f\"Normal distribution (μ=0, σ=1):\")\n",
    "print(f\"Mean: {np.mean(normal_samples):.3f}\")\n",
    "print(f\"Std: {np.std(normal_samples):.3f}\")\n",
    "print()\n",
    "\n",
    "# Uniform distribution\n",
    "uniform_samples = np.random.uniform(low=-2, high=2, size=1000)\n",
    "print(f\"Uniform distribution [-2, 2]:\")\n",
    "print(f\"Min: {np.min(uniform_samples):.3f}\")\n",
    "print(f\"Max: {np.max(uniform_samples):.3f}\")\n",
    "print(f\"Mean: {np.mean(uniform_samples):.3f}\")\n",
    "print()\n",
    "\n",
    "# Exponential distribution\n",
    "exponential_samples = np.random.exponential(scale=2, size=1000)\n",
    "print(f\"Exponential distribution (scale=2):\")\n",
    "print(f\"Mean: {np.mean(exponential_samples):.3f}\")\n",
    "print(f\"Median: {np.median(exponential_samples):.3f}\")\n",
    "print()\n",
    "\n",
    "# Poisson distribution\n",
    "poisson_samples = np.random.poisson(lam=3, size=1000)\n",
    "print(f\"Poisson distribution (λ=3):\")\n",
    "print(f\"Mean: {np.mean(poisson_samples):.3f}\")\n",
    "print(f\"Variance: {np.var(poisson_samples):.3f}\")\n",
    "print()\n",
    "\n",
    "# Binomial distribution\n",
    "binomial_samples = np.random.binomial(n=10, p=0.3, size=1000)\n",
    "print(f\"Binomial distribution (n=10, p=0.3):\")\n",
    "print(f\"Mean: {np.mean(binomial_samples):.3f}\")\n",
    "print(f\"Expected mean: {10 * 0.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random sampling applications\n",
    "print(\"Random sampling applications:\\n\")\n",
    "\n",
    "# Monte Carlo estimation of π\n",
    "def estimate_pi(n_samples):\n",
    "    # Generate random points in [0,1] x [0,1]\n",
    "    x = np.random.uniform(0, 1, n_samples)\n",
    "    y = np.random.uniform(0, 1, n_samples)\n",
    "    \n",
    "    # Count points inside unit circle\n",
    "    inside_circle = (x**2 + y**2) <= 1\n",
    "    pi_estimate = 4 * np.sum(inside_circle) / n_samples\n",
    "    \n",
    "    return pi_estimate\n",
    "\n",
    "for n in [1000, 10000, 100000]:\n",
    "    pi_est = estimate_pi(n)\n",
    "    error = abs(pi_est - np.pi)\n",
    "    print(f\"π estimate with {n:6d} samples: {pi_est:.6f} (error: {error:.6f})\")\n",
    "print(f\"True value of π: {np.pi:.6f}\")\n",
    "print()\n",
    "\n",
    "# Bootstrap sampling\n",
    "print(\"Bootstrap sampling example:\")\n",
    "data = np.random.normal(100, 15, 50)  # Original sample\n",
    "n_bootstrap = 1000\n",
    "bootstrap_means = []\n",
    "\n",
    "for _ in range(n_bootstrap):\n",
    "    # Resample with replacement\n",
    "    bootstrap_sample = np.random.choice(data, size=len(data), replace=True)\n",
    "    bootstrap_means.append(np.mean(bootstrap_sample))\n",
    "\n",
    "bootstrap_means = np.array(bootstrap_means)\n",
    "print(f\"Original sample mean: {np.mean(data):.3f}\")\n",
    "print(f\"Bootstrap mean of means: {np.mean(bootstrap_means):.3f}\")\n",
    "print(f\"Bootstrap std of means: {np.std(bootstrap_means):.3f}\")\n",
    "print(f\"95% CI: [{np.percentile(bootstrap_means, 2.5):.3f}, {np.percentile(bootstrap_means, 97.5):.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. File I/O {#file-io}\n",
    "\n",
    "NumPy provides functions to save and load arrays from files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating sample data for file I/O\n",
    "data_1d = np.array([1, 2, 3, 4, 5])\n",
    "data_2d = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "data_mixed = {\n",
    "    'integers': np.arange(10),\n",
    "    'floats': np.random.randn(5),\n",
    "    'matrix': np.random.randint(0, 10, (3, 3))\n",
    "}\n",
    "\n",
    "print(\"Sample data for file I/O:\")\n",
    "print(f\"1D data: {data_1d}\")\n",
    "print(f\"2D data:\\n{data_2d}\")\n",
    "print(f\"Mixed data keys: {list(data_mixed.keys())}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary format (.npy and .npz)\n",
    "print(\"Binary format I/O:\\n\")\n",
    "\n",
    "# Save single array (.npy)\n",
    "np.save('array_1d.npy', data_1d)\n",
    "np.save('array_2d.npy', data_2d)\n",
    "print(\"Saved arrays to .npy files\")\n",
    "\n",
    "# Load single array\n",
    "loaded_1d = np.load('array_1d.npy')\n",
    "loaded_2d = np.load('array_2d.npy')\n",
    "print(f\"Loaded 1D array: {loaded_1d}\")\n",
    "print(f\"Loaded 2D array:\\n{loaded_2d}\")\n",
    "print()\n",
    "\n",
    "# Save multiple arrays (.npz)\n",
    "np.savez('multiple_arrays.npz', **data_mixed)\n",
    "np.savez_compressed('multiple_arrays_compressed.npz', **data_mixed)\n",
    "print(\"Saved multiple arrays to .npz files\")\n",
    "\n",
    "# Load multiple arrays\n",
    "loaded_data = np.load('multiple_arrays.npz')\n",
    "print(f\"Loaded keys: {list(loaded_data.keys())}\")\n",
    "print(f\"Loaded integers: {loaded_data['integers']}\")\n",
    "print(f\"Loaded matrix:\\n{loaded_data['matrix']}\")\n",
    "\n",
    "# Close the loaded file\n",
    "loaded_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text format I/O\n",
    "print(\"Text format I/O:\\n\")\n",
    "\n",
    "# Save to text file\n",
    "np.savetxt('array_2d.txt', data_2d, fmt='%d', delimiter=',')\n",
    "print(\"Saved 2D array to text file\")\n",
    "\n",
    "# Load from text file\n",
    "loaded_text = np.loadtxt('array_2d.txt', delimiter=',')\n",
    "print(f\"Loaded from text:\\n{loaded_text}\")\n",
    "print(f\"Data type: {loaded_text.dtype}\")\n",
    "print()\n",
    "\n",
    "# Save with headers and formatting\n",
    "float_data = np.random.randn(5, 3)\n",
    "np.savetxt('formatted_data.txt', \n",
    "           float_data, \n",
    "           fmt='%.3f', \n",
    "           delimiter='\\t',\n",
    "           header='Col1\\tCol2\\tCol3',\n",
    "           comments='')\n",
    "\n",
    "print(\"Content of formatted file:\")\n",
    "with open('formatted_data.txt', 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        print(line.strip())\n",
    "        if i >= 5:  # Show first few lines\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV-like data with mixed types\n",
    "print(\"\\nStructured data I/O:\\n\")\n",
    "\n",
    "# Create structured array\n",
    "names = ['Alice', 'Bob', 'Charlie', 'Diana']\n",
    "ages = [25, 30, 35, 28]\n",
    "scores = [85.5, 92.3, 78.8, 96.1]\n",
    "\n",
    "# Create structured array\n",
    "structured_data = np.array(list(zip(names, ages, scores)),\n",
    "                          dtype=[('name', 'U10'), ('age', 'i4'), ('score', 'f4')])\n",
    "\n",
    "print(f\"Structured array:\\n{structured_data}\")\n",
    "print(f\"Names: {structured_data['name']}\")\n",
    "print(f\"Ages: {structured_data['age']}\")\n",
    "print(f\"Scores: {structured_data['score']}\")\n",
    "print()\n",
    "\n",
    "# Save structured data\n",
    "np.save('structured_data.npy', structured_data)\n",
    "\n",
    "# Load structured data\n",
    "loaded_structured = np.load('structured_data.npy')\n",
    "print(f\"Loaded structured data:\\n{loaded_structured}\")\n",
    "print(f\"Bob's score: {loaded_structured[loaded_structured['name'] == 'Bob']['score'][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Performance and Memory {#performance}\n",
    "\n",
    "Understanding NumPy's performance characteristics and memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance comparison: NumPy vs Pure Python\n",
    "print(\"Performance comparison: NumPy vs Pure Python\\n\")\n",
    "\n",
    "# Create large datasets\n",
    "size = 1_000_000\n",
    "python_list = list(range(size))\n",
    "numpy_array = np.arange(size)\n",
    "\n",
    "print(f\"Dataset size: {size:,} elements\")\n",
    "print()\n",
    "\n",
    "# Time pure Python operation\n",
    "start_time = time.time()\n",
    "python_sum = sum(x * 2 for x in python_list)\n",
    "python_time = time.time() - start_time\n",
    "\n",
    "# Time NumPy operation\n",
    "start_time = time.time()\n",
    "numpy_sum = np.sum(numpy_array * 2)\n",
    "numpy_time = time.time() - start_time\n",
    "\n",
    "print(f\"Pure Python time: {python_time:.4f} seconds\")\n",
    "print(f\"NumPy time: {numpy_time:.4f} seconds\")\n",
    "print(f\"Speedup: {python_time / numpy_time:.1f}x\")\n",
    "print(f\"Results equal: {python_sum == numpy_sum}\")\n",
    "print()\n",
    "\n",
    "# Memory usage comparison\n",
    "import sys\n",
    "\n",
    "python_memory = sys.getsizeof(python_list)\n",
    "numpy_memory = numpy_array.nbytes\n",
    "\n",
    "print(f\"Python list memory: {python_memory:,} bytes ({python_memory/1024/1024:.1f} MB)\")\n",
    "print(f\"NumPy array memory: {numpy_memory:,} bytes ({numpy_memory/1024/1024:.1f} MB)\")\n",
    "print(f\"Memory ratio: {python_memory / numpy_memory:.1f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Views vs Copies\n",
    "print(\"Views vs Copies:\\n\")\n",
    "\n",
    "original = np.arange(12).reshape(3, 4)\n",
    "print(f\"Original array:\\n{original}\")\n",
    "print(f\"Original id: {id(original)}\")\n",
    "print()\n",
    "\n",
    "# View (shares data)\n",
    "view = original[1:, :2]  # Slicing creates a view\n",
    "print(f\"View (slice):\\n{view}\")\n",
    "print(f\"View id: {id(view)}\")\n",
    "print(f\"Shares memory: {np.shares_memory(original, view)}\")\n",
    "print(f\"View base is original: {view.base is original}\")\n",
    "print()\n",
    "\n",
    "# Modify view and see effect on original\n",
    "view[0, 0] = 999\n",
    "print(f\"After modifying view:\\n{original}\")\n",
    "print()\n",
    "\n",
    "# Copy (independent data)\n",
    "copy = original.copy()\n",
    "print(f\"Copy id: {id(copy)}\")\n",
    "print(f\"Shares memory: {np.shares_memory(original, copy)}\")\n",
    "copy[0, 0] = 777\n",
    "print(f\"After modifying copy:\")\n",
    "print(f\"Original:\\n{original}\")\n",
    "print(f\"Copy:\\n{copy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory layout and performance\n",
    "print(\"Memory layout and performance:\\n\")\n",
    "\n",
    "# Create arrays with different memory layouts\n",
    "size = 1000\n",
    "c_order = np.arange(size * size).reshape(size, size)  # C-style (row-major)\n",
    "f_order = np.asfortranarray(c_order)  # Fortran-style (column-major)\n",
    "\n",
    "print(f\"C-order flags: C_CONTIGUOUS={c_order.flags['C_CONTIGUOUS']}, F_CONTIGUOUS={c_order.flags['F_CONTIGUOUS']}\")\n",
    "print(f\"F-order flags: C_CONTIGUOUS={f_order.flags['C_CONTIGUOUS']}, F_CONTIGUOUS={f_order.flags['F_CONTIGUOUS']}\")\n",
    "print()\n",
    "\n",
    "# Performance test: row-wise access\n",
    "def time_row_access(arr, name):\n",
    "    start = time.time()\n",
    "    result = 0\n",
    "    for i in range(100):  # Reduced iterations for faster execution\n",
    "        for j in range(100):\n",
    "            result += arr[i, j]\n",
    "    return time.time() - start\n",
    "\n",
    "# Test with smaller arrays for demonstration\n",
    "small_c = c_order[:100, :100]\n",
    "small_f = f_order[:100, :100]\n",
    "\n",
    "c_time = time_row_access(small_c, \"C-order\")\n",
    "f_time = time_row_access(small_f, \"F-order\")\n",
    "\n",
    "print(f\"Row-wise access time:\")\n",
    "print(f\"C-order: {c_time:.4f} seconds\")\n",
    "print(f\"F-order: {f_time:.4f} seconds\")\n",
    "print(f\"C-order is {f_time/c_time:.1f}x faster for row-wise access\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization benefits\n",
    "print(\"Vectorization benefits:\\n\")\n",
    "\n",
    "def python_operations(arr1, arr2):\n",
    "    result = []\n",
    "    for i in range(len(arr1)):\n",
    "        result.append(arr1[i] ** 2 + arr2[i] ** 2)\n",
    "    return result\n",
    "\n",
    "def numpy_operations(arr1, arr2):\n",
    "    return arr1 ** 2 + arr2 ** 2\n",
    "\n",
    "# Test data\n",
    "size = 100_000\n",
    "list1 = list(range(size))\n",
    "list2 = list(range(size, 2 * size))\n",
    "array1 = np.array(list1)\n",
    "array2 = np.array(list2)\n",
    "\n",
    "# Time both approaches\n",
    "start = time.time()\n",
    "python_result = python_operations(list1, list2)\n",
    "python_time = time.time() - start\n",
    "\n",
    "start = time.time()\n",
    "numpy_result = numpy_operations(array1, array2)\n",
    "numpy_time = time.time() - start\n",
    "\n",
    "print(f\"Array size: {size:,}\")\n",
    "print(f\"Python loop time: {python_time:.4f} seconds\")\n",
    "print(f\"NumPy vectorized time: {numpy_time:.4f} seconds\")\n",
    "print(f\"Speedup: {python_time / numpy_time:.1f}x\")\n",
    "print(f\"Results equal: {np.allclose(python_result, numpy_result)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Real-world Applications {#applications}\n",
    "\n",
    "Practical examples showing how NumPy is used in real scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image processing example\n",
    "print(\"Image Processing with NumPy:\\n\")\n",
    "\n",
    "# Create a synthetic image (grayscale)\n",
    "height, width = 100, 100\n",
    "x, y = np.meshgrid(np.linspace(-1, 1, width), np.linspace(-1, 1, height))\n",
    "image = np.exp(-(x**2 + y**2) / 0.3)  # Gaussian blob\n",
    "\n",
    "print(f\"Image shape: {image.shape}\")\n",
    "print(f\"Image data type: {image.dtype}\")\n",
    "print(f\"Image range: [{image.min():.3f}, {image.max():.3f}]\")\n",
    "\n",
    "# Image operations\n",
    "print(\"\\nImage operations:\")\n",
    "\n",
    "# Normalize to 0-255 range\n",
    "image_normalized = ((image - image.min()) / (image.max() - image.min()) * 255).astype(np.uint8)\n",
    "print(f\"Normalized range: [{image_normalized.min()}, {image_normalized.max()}]\")\n",
    "\n",
    "# Apply threshold\n",
    "threshold = 128\n",
    "binary_image = (image_normalized > threshold).astype(np.uint8) * 255\n",
    "print(f\"Binary image unique values: {np.unique(binary_image)}\")\n",
    "\n",
    "# Simple blur (averaging filter)\n",
    "kernel_size = 5\n",
    "kernel = np.ones((kernel_size, kernel_size)) / (kernel_size ** 2)\n",
    "# Note: In real applications, you'd use scipy.ndimage.convolve\n",
    "print(f\"Blur kernel shape: {kernel.shape}\")\n",
    "print(f\"Kernel sum: {kernel.sum():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signal processing example\n",
    "print(\"Signal Processing with NumPy:\\n\")\n",
    "\n",
    "# Generate a noisy signal\n",
    "t = np.linspace(0, 2, 1000)\n",
    "frequency1, frequency2 = 5, 20\n",
    "clean_signal = (np.sin(2 * np.pi * frequency1 * t) + \n",
    "                0.5 * np.cos(2 * np.pi * frequency2 * t))\n",
    "noise = np.random.normal(0, 0.2, len(t))\n",
    "noisy_signal = clean_signal + noise\n",
    "\n",
    "print(f\"Signal length: {len(t)}\")\n",
    "print(f\"Time range: {t[0]:.1f} to {t[-1]:.1f} seconds\")\n",
    "print(f\"Signal range: [{noisy_signal.min():.3f}, {noisy_signal.max():.3f}]\")\n",
    "\n",
    "# Signal analysis\n",
    "print(\"\\nSignal statistics:\")\n",
    "print(f\"Mean: {np.mean(noisy_signal):.3f}\")\n",
    "print(f\"RMS: {np.sqrt(np.mean(noisy_signal**2)):.3f}\")\n",
    "print(f\"Peak-to-peak: {np.ptp(noisy_signal):.3f}\")\n",
    "\n",
    "# Simple moving average filter\n",
    "window_size = 21\n",
    "filtered_signal = np.convolve(noisy_signal, \n",
    "                             np.ones(window_size)/window_size, \n",
    "                             mode='same')\n",
    "print(f\"\\nFiltered signal RMS: {np.sqrt(np.mean(filtered_signal**2)):.3f}\")\n",
    "\n",
    "# Find peaks (simple approach)\n",
    "# Find local maxima\n",
    "peak_indices = []\n",
    "for i in range(1, len(filtered_signal) - 1):\n",
    "    if (filtered_signal[i] > filtered_signal[i-1] and \n",
    "        filtered_signal[i] > filtered_signal[i+1] and \n",
    "        filtered_signal[i] > 0.5):\n",
    "        peak_indices.append(i)\n",
    "\n",
    "print(f\"Number of peaks found: {len(peak_indices)}\")\n",
    "if peak_indices:\n",
    "    peak_times = t[peak_indices]\n",
    "    print(f\"First few peak times: {peak_times[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Financial analysis example\n",
    "print(\"Financial Analysis with NumPy:\\n\")\n",
    "\n",
    "# Generate synthetic stock price data\n",
    "np.random.seed(42)\n",
    "days = 252  # Trading days in a year\n",
    "initial_price = 100\n",
    "daily_returns = np.random.normal(0.001, 0.02, days)  # Mean return 0.1% with 2% volatility\n",
    "prices = initial_price * np.exp(np.cumsum(daily_returns))\n",
    "\n",
    "print(f\"Stock analysis over {days} days:\")\n",
    "print(f\"Initial price: ${initial_price:.2f}\")\n",
    "print(f\"Final price: ${prices[-1]:.2f}\")\n",
    "print(f\"Total return: {(prices[-1] / initial_price - 1) * 100:.2f}%\")\n",
    "print()\n",
    "\n",
    "# Calculate financial metrics\n",
    "returns = np.diff(prices) / prices[:-1]  # Daily returns\n",
    "print(\"Risk metrics:\")\n",
    "print(f\"Daily volatility: {np.std(returns) * 100:.2f}%\")\n",
    "print(f\"Annualized volatility: {np.std(returns) * np.sqrt(252) * 100:.2f}%\")\n",
    "print(f\"Sharpe ratio (assuming 0% risk-free rate): {np.mean(returns) / np.std(returns) * np.sqrt(252):.2f}\")\n",
    "print()\n",
    "\n",
    "# Moving averages\n",
    "ma_short = 20\n",
    "ma_long = 50\n",
    "\n",
    "# Calculate moving averages using convolution\n",
    "ma_20 = np.convolve(prices, np.ones(ma_short)/ma_short, mode='valid')\n",
    "ma_50 = np.convolve(prices, np.ones(ma_long)/ma_long, mode='valid')\n",
    "\n",
    "print(f\"Moving averages:\")\n",
    "print(f\"20-day MA (last): ${ma_20[-1]:.2f}\")\n",
    "print(f\"50-day MA (last): ${ma_50[-1]:.2f}\")\n",
    "\n",
    "# Value at Risk (VaR) calculation\n",
    "confidence_level = 0.05  # 95% confidence\n",
    "var_1day = np.percentile(returns, confidence_level * 100)\n",
    "print(f\"\\nValue at Risk (95% confidence):\")\n",
    "print(f\"1-day VaR: {var_1day * 100:.2f}%\")\n",
    "print(f\"1-day VaR in $: ${var_1day * prices[-1]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scientific computing example: Numerical integration\n",
    "print(\"Scientific Computing: Numerical Integration\\n\")\n",
    "\n",
    "# Define a function to integrate\n",
    "def f(x):\n",
    "    return np.exp(-x**2) * np.cos(x)\n",
    "\n",
    "# Numerical integration using Trapezoidal rule\n",
    "def trapezoidal_rule(func, a, b, n):\n",
    "    x = np.linspace(a, b, n + 1)\n",
    "    y = func(x)\n",
    "    h = (b - a) / n\n",
    "    return h * (0.5 * y[0] + np.sum(y[1:-1]) + 0.5 * y[-1])\n",
    "\n",
    "# Simpson's rule\n",
    "def simpsons_rule(func, a, b, n):\n",
    "    if n % 2 != 0:\n",
    "        n += 1  # Simpson's rule requires even number of intervals\n",
    "    x = np.linspace(a, b, n + 1)\n",
    "    y = func(x)\n",
    "    h = (b - a) / n\n",
    "    return h/3 * (y[0] + 4*np.sum(y[1::2]) + 2*np.sum(y[2:-1:2]) + y[-1])\n",
    "\n",
    "# Integration limits\n",
    "a, b = -2, 2\n",
    "\n",
    "# Test different numbers of intervals\n",
    "print(f\"Integrating exp(-x²)cos(x) from {a} to {b}:\\n\")\n",
    "print(\"Method\\t\\tN\\tResult\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "for n in [10, 100, 1000]:\n",
    "    trap_result = trapezoidal_rule(f, a, b, n)\n",
    "    simp_result = simpsons_rule(f, a, b, n)\n",
    "    \n",
    "    print(f\"Trapezoidal\\t{n}\\t{trap_result:.6f}\")\n",
    "    print(f\"Simpson's\\t{n}\\t{simp_result:.6f}\")\n",
    "    print()\n",
    "\n",
    "# Monte Carlo integration\n",
    "def monte_carlo_integration(func, a, b, n):\n",
    "    x_random = np.random.uniform(a, b, n)\n",
    "    y_values = func(x_random)\n",
    "    return (b - a) * np.mean(y_values)\n",
    "\n",
    "print(\"Monte Carlo method:\")\n",
    "for n in [1000, 10000, 100000]:\n",
    "    mc_result = monte_carlo_integration(f, a, b, n)\n",
    "    print(f\"N = {n:6d}: {mc_result:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up created files\n",
    "import os\n",
    "files_to_remove = [\n",
    "    'array_1d.npy', 'array_2d.npy', 'multiple_arrays.npz', \n",
    "    'multiple_arrays_compressed.npz', 'array_2d.txt', 'formatted_data.txt',\n",
    "    'structured_data.npy'\n",
    "]\n",
    "\n",
    "removed_files = []\n",
    "for file in files_to_remove:\n",
    "    if os.path.exists(file):\n",
    "        os.remove(file)\n",
    "        removed_files.append(file)\n",
    "\n",
    "if removed_files:\n",
    "    print(f\"\\nCleaned up {len(removed_files)} temporary files\")\n",
    "else:\n",
    "    print(\"\\nNo temporary files to clean up\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Best Practices\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Arrays**: NumPy arrays are the foundation - understand creation, indexing, and basic operations\n",
    "2. **Vectorization**: Use vectorized operations instead of loops for better performance\n",
    "3. **Broadcasting**: Leverage broadcasting for operations on arrays of different shapes\n",
    "4. **Memory**: Understand views vs. copies and memory layout for optimal performance\n",
    "5. **Dtypes**: Choose appropriate data types to optimize memory usage and performance\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "1. **Use vectorized operations**: Avoid explicit loops when possible\n",
    "2. **Preallocate arrays**: Use `np.zeros()`, `np.empty()` instead of growing arrays\n",
    "3. **Choose right dtype**: Use `float32` instead of `float64` when precision allows\n",
    "4. **Understand memory layout**: Consider C vs. Fortran order for your access patterns\n",
    "5. **Use views when possible**: Avoid unnecessary copying of data\n",
    "6. **Leverage broadcasting**: Write concise code for operations on different-shaped arrays\n",
    "\n",
    "### Performance Tips\n",
    "\n",
    "- Use NumPy's built-in functions instead of implementing your own\n",
    "- Consider using `numba` or `Cython` for performance-critical loops\n",
    "- Profile your code to identify bottlenecks\n",
    "- Use appropriate algorithms (e.g., FFT for convolutions on large arrays)\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Explore SciPy for advanced scientific computing functions\n",
    "- Learn pandas for data analysis workflows\n",
    "- Study scikit-learn for machine learning applications\n",
    "- Practice with real datasets to solidify understanding\n",
    "- Explore NumPy's C API for extending Python with compiled code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
